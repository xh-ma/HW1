{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd7a3317",
   "metadata": {},
   "source": [
    "# \"Pre-lecture\" HW07"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4c91b8",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "**1. Simple Linear Regression vs. Multiple Linear Regression**\n",
    "- Simple Linear Regression involves only one independent (predictor) variable and one dependent (response) variable. The model fits a straight line (or linear relationship) between the predictor and response:\n",
    "$$y = \\beta_0 + \\beta_1 x$$\n",
    "    - where y is the dependent variable, x is the single predictor variable, and B0 y-intercept and B1 as the slope.\n",
    "- Multiple Linear Regression includes two or more predictor variables, with the relationship given by $$ y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_n x_n $$\n",
    "This form allows for a more complex model that can account for multiple factors influencing y simultaneously.\n",
    "- Multiple Linear Regression allows for modeling the effect of multiple predictors simultaneously, providing a more accurate and flexible representation of complex relationships compared to Simple Linear Regression, which only considers one predictor.\n",
    "\n",
    "\n",
    "**2. Continuous vs. Indicator Variables in Simple Linear Regression**\n",
    "- A continuous variable takes on any value within a range and directly affects the slope of the fitted line. With a continuous predictor, the model estimates a linear trend across the range of values for that variable.\n",
    "- An indicator variable, typically binary (0 or 1), represents categorical data. This variable shifts the intercept, creating two different fitted lines or parallel trends for each category, without changing the slope unless interactions are included.\n",
    "\n",
    "\n",
    "**3. Introducing an Indicator Variable Alongside a Continuous Variable in Multiple Linear Regression**\n",
    "-  Adding an indicator variable along with a continuous variable in a Multiple Linear Regression model enables the model to distinguish between categories while modeling the trend across the continuous predictor. The result is a model where the intercept differs by category (due to the indicator) but maintains a common slope for the continuous variable unless interactions are included.\n",
    "- In Simple Linear Regression (with only a continuous variable), the model fits a single line to the data. In Multiple Linear Regression (adding an indicator), the model fits two lines with different intercepts, one for each category of the indicator, capturing the category-specific baselines.\n",
    "\n",
    "\n",
    "**4. Adding an Interaction between a Continuous and an Indicator Variable in Multiple Linear Regression**\n",
    "- Adding an interaction term between a continuous and an indicator variable allows the slope of the continuous variable to differ for each category represented by the indicator. The model form becomes $y = \\beta_0 + \\beta_1 x + \\beta_2 d + \\beta_3 (x \\cdot d)$ where, d is the indicator variable. This enables the model to capture differing trends across categories.\n",
    "-  With the interaction term, the model now fits different slopes for each category, allowing it to reflect varying effects of the continuous predictor depending on category membership.\n",
    "\n",
    "\n",
    "**5. Multiple Linear Regression Model Based Only on Indicator Variables from a Non-Binary Categorical Variable**\n",
    "- When the predictors consist solely of indicator variables derived from a categorical variable with multiple levels, the model captures shifts in the response variable for each category. The behavior reflects expected differences in the response across discrete, non-ordered categories.\n",
    "- regression model: $y = \\beta_0 + \\beta_1 d_1 + \\beta_2 d_2 + \\ldots + \\beta_{k-1} d_{k-1}$ The categorical variable with k levels is represented by k−1 indicator variables. Each indicator represents a group, with the last group as the baseline.\n",
    "- The baseline group is the reference category that doesn’t have its own indicator variable. The coefficients of the other categories show the difference in the outcome relative to the baseline group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130157fb",
   "metadata": {},
   "source": [
    "### Summary of Interactions with ChatGPT\n",
    "\n",
    "1. **Simple vs. Multiple Linear Regression**  \n",
    "   - **Simple Linear Regression (SLR)**: Uses a single predictor to explain a dependent variable.\n",
    "   - **Multiple Linear Regression (MLR)**: Includes multiple predictors, allowing it to capture more complex relationships and increase accuracy.\n",
    "\n",
    "2. **Continuous vs. Indicator Variables in SLR**  \n",
    "   - **Continuous Variables**: Imply a steady, linear relationship with the dependent variable.\n",
    "   - **Indicator (Binary) Variables**: Partition the data into two distinct means (different intercepts).\n",
    "\n",
    "3. **MLR with a Continuous and an Indicator Variable**  \n",
    "   - Adding an indicator variable to a continuous predictor in MLR allows the model to account for both a continuous effect and a categorical distinction, capturing different average outcomes for each group.\n",
    "\n",
    "4. **Interaction Between Continuous and Indicator Variables**  \n",
    "   - Adding an interaction term between a continuous and an indicator variable enables the model to have different slopes for each category defined by the indicator, representing a varying effect of the continuous predictor across groups.\n",
    "\n",
    "5. **MLR Using Only Indicator Variables from a Non-Binary Categorical Variable**  \n",
    "   - When modeling with a categorical variable that has multiple categories, indicator (dummy) variables are created for each category (except one baseline).\n",
    "   - This structure models distinct means for each category relative to the baseline, using binary encoding for each category indicator.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26afba64",
   "metadata": {},
   "source": [
    "[Chatbot transcript](https://chatgpt.com/share/67321d84-0498-800f-b486-3703266056ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57148824",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "**Variables:**\n",
    "- Outcome: $Y$ (sales)\n",
    "- Predictors:\n",
    "  - $X_{\\text{TV}}$: TV advertising budget\n",
    "  - $X_{\\text{Online}}$: Online advertising budget\n",
    "\n",
    "**Models:**\n",
    "\n",
    "1. Without Interaction:\n",
    "\n",
    "   $$\n",
    "   Y = \\beta_0 + \\beta_1 X_{\\text{TV}} + \\beta_2 X_{\\text{Online}} + \\epsilon\n",
    "   $$\n",
    "\n",
    "2. With Interaction:\n",
    "\n",
    "   $$\n",
    "   Y = \\beta_0 + \\beta_1 X_{\\text{TV}} + \\beta_2 X_{\\text{Online}} + \\beta_3 (X_{\\text{TV}} \\times X_{\\text{Online}}) + \\epsilon\n",
    "   $$\n",
    "\n",
    "**Interpretation of Models:**\n",
    "- *Without Interaction*: Assumes independent, additive effects of TV and online budgets on sales.\n",
    "- *With Interaction*: Allows the effect of one budget on sales to vary based on the other, capturing any synergistic effect.\n",
    "\n",
    "**Binary Predictor Case (High vs. Low Budgets):**\n",
    "- Let $X_{\\text{TV}} = 1$ if high, $0$ if low; and $X_{\\text{Online}} = 1$ if high, $0$ if low.\n",
    "\n",
    "1. Without Interaction:\n",
    "\n",
    "   $$\n",
    "   Y = \\beta_0 + \\beta_1 \\cdot 1(X_{\\text{TV}}) + \\beta_2 \\cdot 1(X_{\\text{Online}}) + \\epsilon\n",
    "   $$\n",
    "\n",
    "2. With Interaction:\n",
    "\n",
    "   $$\n",
    "   Y = \\beta_0 + \\beta_1 \\cdot 1(X_{\\text{TV}}) + \\beta_2 \\cdot 1(X_{\\text{Online}}) + \\beta_3 \\cdot 1(X_{\\text{TV}}) \\cdot 1(X_{\\text{Online}}) + \\epsilon\n",
    "   $$\n",
    "\n",
    "\n",
    "A meaningful interaction between TV and online advertising budgets is likely. The effectiveness of one medium could depend on the level of spending on the other, such as a high online budget amplifying the impact of TV ads. Including an interaction term in the model will capture these potential combined effects, leading to more accurate predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0937e12d",
   "metadata": {},
   "source": [
    "### Summary of Interactions with ChatGPT\n",
    "In this session, we explored a scenario where a company uses both TV and online advertising to drive sales. We identified sales as the outcome variable, with TV and online advertising budgets as the predictor variables. We discussed two linear models:\n",
    "\n",
    "1. Without Interaction: A model assuming independent, additive effects of TV and online advertising on sales.\n",
    "2. With Interaction: A model including an interaction term to capture the combined effect of TV and online budgets, allowing for potential synergy or diminishing returns when both budgets are high.\n",
    "We also considered a situation where budgets are categorized as high or low (binary variables), updating the models accordingly. Finally, we concluded that including the interaction term would likely provide more meaningful predictions, as the effectiveness of one type of ad spending may depend on the level of the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753a9bfc",
   "metadata": {},
   "source": [
    "[Chatbot transcript](https://chatgpt.com/share/67324aa4-4984-800f-99e1-f0022c44b940)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9cca6f",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a716472",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ef9a3a",
   "metadata": {},
   "source": [
    "#### Explanation of the Code\n",
    "\n",
    "##### **Linear Regression (Additive Model)**\n",
    "\n",
    "1. **Outcome Variable**:\n",
    "   - `happiness_score` is a continuous outcome.\n",
    "\n",
    "2. **Predictors**:\n",
    "   - `income` is a continuous predictor.\n",
    "   - `gender` is a binary variable (e.g., Male/Female).\n",
    "   - `region` is a categorical variable with multiple levels (e.g., North, South, East, West).\n",
    "   - `C()` in the formula tells Python to treat a variable as categorical.\n",
    "\n",
    "3. **Formula**:\n",
    "   The formula specifies how predictors contribute additively to the outcome:\n",
    "$\n",
    "   \\text{happiness_score} = \\beta_0 + \\beta_1 \\text{income} + \\beta_2 \\text{gender} + \\beta_3 1(\\text{region = South}) + \\beta_4 1(\\text{region = East}) + \\beta_5 1(\\text{region = West}) + \\epsilon\n",
    "$\n",
    "\n",
    "4. **Output**:\n",
    "   - Use `result_linear.summary()` to view model coefficients, p-values, and diagnostics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b932a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Fit a linear regression model\n",
    "model_linear = smf.ols('happiness_score ~ income + C(gender) + C(region)', data=data)\n",
    "result_linear = model_linear.fit()\n",
    "\n",
    "# Print the summary\n",
    "print(result_linear.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3022e699",
   "metadata": {},
   "source": [
    "##### **Logistic Regression (Binary Outcome)**\n",
    "\n",
    "1. **Outcome Variable**:\n",
    "   - `is_satisfied` is a binary variable derived from `satisfaction_level`, where values greater than 3 are encoded as 1 (satisfied), and the rest as 0.\n",
    "\n",
    "2. **Predictors**:\n",
    "   - Same as in linear regression: a combination of continuous, binary, and categorical predictors.\n",
    "\n",
    "3. **Formula**:\n",
    "   The logistic regression formula relates predictors to the log-odds of the binary outcome:\n",
    "$\n",
    "   \\text{logit}(\\pi) = \\beta_0 + \\beta_1 \\text{income} + \\beta_2 \\text{gender} + \\beta_3 1(\\text{region = South}) + \\beta_4 1(\\text{region = East}) + \\beta_5 1(\\text{region = West})\n",
    "$\n",
    "\n",
    "4. **Steps**:\n",
    "   - Create the binary outcome using: \n",
    "     ```python\n",
    "     data['is_satisfied'] = (data['satisfaction_level'] > 3).astype(int)\n",
    "     ```\n",
    "   - Use `C()` for categorical variables in the model.\n",
    "   - Use `result_logistic.summary()` to view model coefficients, p-values, and fit diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5fc03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Create binary outcome variable\n",
    "data['is_satisfied'] = (data['satisfaction_level'] > 3).astype(int)\n",
    "\n",
    "# Fit a logistic regression model\n",
    "model_logistic = smf.logit('is_satisfied ~ income + C(gender) + C(region)', data=data)\n",
    "result_logistic = model_logistic.fit()\n",
    "\n",
    "# Print the summary\n",
    "print(result_logistic.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0311f6b",
   "metadata": {},
   "source": [
    "##### **Key Notes**:\n",
    "- The `statsmodels.formula.api` module is used for convenient formula-based model specification.\n",
    "- Python automatically selects a reference group for categorical variables unless specified otherwise.\n",
    "- The `summary()` method provides a detailed output of the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36ff5fb",
   "metadata": {},
   "source": [
    "2. \n",
    "**Step 1: Linear Regression with Interaction Terms**\n",
    "#### Objective:\n",
    "Include interaction terms to explore whether the effect of one predictor depends on the value of another.\n",
    "\n",
    "#### Example Variables:\n",
    "- **Outcome (continuous)**: `happiness_score`\n",
    "- **Predictors**:\n",
    "  - `income` (continuous)\n",
    "  - `gender` (binary: Male/Female)\n",
    "\n",
    "#### Model Specification:\n",
    "$\n",
    "\\text{happiness_score} = \\beta_0 + \\beta_1 \\text{income} + \\beta_2 \\text{gender} + \\beta_3 (\\text{income} \\cdot \\text{gender}) + \\epsilon\n",
    "$\n",
    "\n",
    "#### Code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1397276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Fit a linear regression model with interaction\n",
    "model_linear_interaction = smf.ols('happiness_score ~ income * C(gender)', data=data)\n",
    "result_linear_interaction = model_linear_interaction.fit()\n",
    "\n",
    "# Print the summary\n",
    "print(result_linear_interaction.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd686042",
   "metadata": {},
   "source": [
    " **Step 2: Logistic Regression with Interaction Terms**\n",
    "#### Objective:\n",
    "Model a binary outcome while considering interactions between predictors.\n",
    "\n",
    "#### Example Variables:\n",
    "- **Outcome (binary)**: `is_satisfied` (satisfaction level > 3)\n",
    "- **Predictors**:\n",
    "  - `income` (continuous)\n",
    "  - `gender` (binary: Male/Female)\n",
    "\n",
    "#### Model Specification:\n",
    "\\[\n",
    "\\text{logit}(\\pi) = \\beta_0 + \\beta_1 \\text{income} + \\beta_2 \\text{gender} + \\beta_3 (\\text{income} \\cdot \\text{gender})\n",
    "\\]\n",
    "\n",
    "#### Code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fa568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Create binary outcome variable\n",
    "data['is_satisfied'] = (data['satisfaction_level'] > 3).astype(int)\n",
    "\n",
    "# Fit a logistic regression model with interaction\n",
    "model_logistic_interaction = smf.logit('is_satisfied ~ income * C(gender)', data=data)\n",
    "result_logistic_interaction = model_logistic_interaction.fit()\n",
    "\n",
    "# Print the summary\n",
    "print(result_logistic_interaction.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb01045",
   "metadata": {},
   "source": [
    "**Restrict to Continuous and Binary Predictors**\n",
    "\n",
    "If we want to include only continuous and binary predictors:\n",
    "\n",
    "- Continuous predictors can remain as-is.\n",
    "- Categorical predictors can be encoded into binary using dummy encoding.\n",
    "\n",
    "For example, if region is categorical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92821429",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['region_north'] = (data['region'] == 'North').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b77cb1b",
   "metadata": {},
   "source": [
    "We can then include region_north as a binary predictor in the model, replacing region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57ce1bf",
   "metadata": {},
   "source": [
    "3. \n",
    "### Interpreting the Linear Regression Model (With Interaction Terms)\n",
    "\n",
    "Consider the **linear regression model** with interaction terms:\n",
    "\n",
    "$$\n",
    "\\text{happiness\\_score} = \\beta_0 + \\beta_1 \\text{income} + \\beta_2 \\text{gender} + \\beta_3 (\\text{income} \\cdot \\text{gender}) + \\epsilon\n",
    "$$\n",
    "\n",
    "#### 1. Main Effects:\n",
    "- **$\\beta_1$ (income)**: This is the effect of `income` on `happiness_score` when `gender` is held constant (for the reference group, say Female, if `gender` is coded 0 for Female and 1 for Male).\n",
    "- **$\\beta_2$ (gender)**: This represents the effect of `gender` on `happiness_score` when `income` is held constant (typically, this will be the difference between Male and Female if `gender` is coded as 0 and 1).\n",
    "\n",
    "#### 2. Interaction Term:\n",
    "- **$\\beta_3$ (income:gender)**: This is the interaction effect. It tells you how the effect of `income` on `happiness_score` changes depending on the value of `gender`. If $\\beta_3$ is significant, the relationship between `income` and `happiness_score` differs by gender.\n",
    "  - For example, if $\\beta_3$ is positive, it might indicate that the effect of `income` on `happiness_score` is stronger for one gender than the other.\n",
    "\n",
    "#### How to Use for Prediction:\n",
    "To make a prediction:\n",
    "1. **Plug in values for predictors** (`income`, `gender`).\n",
    "2. **Apply the equation** using the estimated coefficients from the model output.\n",
    "\n",
    "For instance:\n",
    "- If `income = 50,000` and `gender = 1` (Male), plug these into the formula:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\beta_0 + \\beta_1 \\times 50000 + \\beta_2 \\times 1 + \\beta_3 \\times (50000 \\times 1)\n",
    "$$\n",
    "\n",
    "- This gives you the predicted `happiness_score`.\n",
    "\n",
    "---\n",
    "\n",
    "### Interpreting the Logistic Regression Model (With Interaction Terms)\n",
    "\n",
    "Consider the logistic regression model:\n",
    "\n",
    "$$\n",
    "\\text{logit}(\\pi) = \\beta_0 + \\beta_1 \\text{income} + \\beta_2 \\text{gender} + \\beta_3 (\\text{income} \\cdot \\text{gender})\n",
    "$$\n",
    "\n",
    "Where $\\pi$ is the probability of being in the \"success\" category (e.g., `is_satisfied = 1`).\n",
    "\n",
    "#### 1. Main Effects:\n",
    "- **$\\beta_1$ (income)**: This is the change in the **log odds** of the outcome (e.g., satisfaction) per unit change in `income`. A positive $\\beta_1$ suggests that as `income` increases, the log odds of being satisfied (or having the outcome = 1) increase.\n",
    "- **$\\beta_2$ (gender)**: This represents the change in the **log odds** of the outcome when `gender` switches from 0 (Female) to 1 (Male). If $\\beta_2$ is positive, it indicates that Males are more likely to be satisfied (or have the outcome = 1) than Females, all else being equal.\n",
    "\n",
    "#### 2. Interaction Term:\n",
    "- **$\\beta_3$ (income:gender)**: This term represents how the **log odds** of the outcome change depending on both `income` and `gender`. If $\\beta_3$ is significant, the effect of `income` on the probability of satisfaction is different for Males and Females.\n",
    "\n",
    "#### How to Use for Prediction (as Linear):\n",
    "Even though we're modeling log odds, let's **interpret it as if it's linear regression** for simplicity:\n",
    "\n",
    "1. **Plug in values for predictors** (`income`, `gender`).\n",
    "2. **Apply the equation** using the estimated coefficients.\n",
    "\n",
    "For instance, if `income = 50,000` and `gender = 1` (Male):\n",
    "\n",
    "$$\n",
    "\\hat{\\text{logit}} = \\beta_0 + \\beta_1 \\times 50000 + \\beta_2 \\times 1 + \\beta_3 \\times (50000 \\times 1)\n",
    "$$\n",
    "\n",
    "- This gives the **logit**, which is the log odds of being in the \"satisfied\" group.\n",
    "- To convert the log odds to a **probability**:\n",
    "\n",
    "$$\n",
    "\\pi = \\frac{1}{1 + e^{-\\hat{\\text{logit}}}}\n",
    "$$\n",
    "\n",
    "This will give you the predicted probability of being satisfied.\n",
    "\n",
    "---\n",
    "\n",
    "### Example Prediction for Logistic Regression:\n",
    "Suppose the model outputs:\n",
    "- $\\beta_0 = -3$\n",
    "- $\\beta_1 = 0.0001$\n",
    "- $\\beta_2 = 0.5$\n",
    "- $\\beta_3 = 0.00005$\n",
    "\n",
    "For a person with `income = 50,000` and `gender = 1` (Male), we would calculate the logit first:\n",
    "\n",
    "$$\n",
    "\\hat{\\text{logit}} = -3 + (0.0001 \\times 50000) + (0.5 \\times 1) + (0.00005 \\times 50000 \\times 1) = -3 + 5 + 0.5 + 2.5 = 5\n",
    "$$\n",
    "\n",
    "Then, convert the logit to probability:\n",
    "\n",
    "$$\n",
    "\\pi = \\frac{1}{1 + e^{-5}} \\approx 0.993\n",
    "$$\n",
    "\n",
    "This means the predicted probability of being satisfied (outcome = 1) is about 99.3%.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways:\n",
    "1. **Linear regression**: Coefficients directly tell you the change in the outcome variable per unit change in predictors.\n",
    "2. **Logistic regression**: Interpreting the coefficients in terms of log odds is more complex, but we simplify it by using them as if they were linear predictors for now.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c410834",
   "metadata": {},
   "source": [
    "4. \n",
    "### Key Elements of the `.summary()` Table\n",
    "\n",
    "For **both linear and logistic regression models**, the `.summary()` table provides the following useful statistics:\n",
    "\n",
    "1. **Coefficients** ($\\beta$ values): These represent the estimated effect of each predictor variable on the outcome.\n",
    "2. **Standard Error (Std Err)**: This indicates the variability or uncertainty in the coefficient estimate.\n",
    "3. **t-Statistic (t)**: For linear regression, this tests if the coefficient is significantly different from zero.\n",
    "4. **p-Value (P>|t|)**: This tells us the probability of observing a coefficient as extreme as the one estimated, assuming the null hypothesis (that the true coefficient is zero) is true.\n",
    "    - A p-value less than 0.05 typically suggests statistical significance.\n",
    "5. **Confidence Interval (CI)**: For both linear and logistic regression, the 95% confidence interval provides a range of values within which the true coefficient likely falls.\n",
    "\n",
    "---\n",
    "\n",
    "### Interpreting the Statistical Evidence\n",
    "\n",
    "#### 1. **Linear Regression Interpretation**\n",
    "\n",
    "Consider the linear regression model:\n",
    "\n",
    "$\n",
    "\\text{happiness\\_score} = \\beta_0 + \\beta_1 \\text{income} + \\beta_2 \\text{gender} + \\beta_3 (\\text{income} \\cdot \\text{gender}) + \\epsilon\n",
    "$\n",
    "\n",
    "##### Coefficients ($\\beta_1$, $\\beta_2$, $\\beta_3$):\n",
    "- **$\\beta_1$ (income)**: If the coefficient is **0.5**, this would mean that for every unit increase in `income`, the predicted `happiness_score` increases by 0.5, **holding `gender` constant**.\n",
    "- **$\\beta_2$ (gender)**: If the coefficient is **2.0**, this would indicate that, on average, being male (if `gender = 1`) increases the `happiness_score` by 2.0 units compared to being female, **holding `income` constant**.\n",
    "- **$\\beta_3$ (income:gender interaction)**: If the coefficient is **0.01**, this suggests that the effect of `income` on `happiness_score` increases by 0.01 for each 1-unit increase in `income`, for males compared to females.\n",
    "\n",
    "##### Standard Error (Std Err):\n",
    "- The **standard error** tells us how much the coefficient estimates vary across different samples. Smaller standard errors mean more reliable estimates.\n",
    "\n",
    "##### t-Statistic and p-Value:\n",
    "- The **t-statistic** tests whether the coefficient is significantly different from zero. A high absolute value (greater than 2) typically means the coefficient is statistically significant.\n",
    "- The **p-value** helps assess statistical significance. If the p-value for a predictor is **less than 0.05**, we reject the null hypothesis that the coefficient is zero (indicating that the predictor is significantly associated with the outcome).\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Logistic Regression Interpretation**\n",
    "\n",
    "Consider the logistic regression model:\n",
    "\n",
    "$\n",
    "\\text{logit}(\\pi) = \\beta_0 + \\beta_1 \\text{income} + \\beta_2 \\text{gender} + \\beta_3 (\\text{income} \\cdot \\text{gender})\n",
    "$\n",
    "\n",
    "##### Coefficients ($\\beta_1$, $\\beta_2$, $\\beta_3$):\n",
    "- **$\\beta_1$ (income)**: If the coefficient is **0.0001**, this means that for every unit increase in `income`, the log odds of being satisfied (outcome = 1) increase by 0.0001. \n",
    "- **$\\beta_2$ (gender)**: If the coefficient is **0.5**, this indicates that being male increases the log odds of being satisfied by 0.5, compared to being female.\n",
    "- **$\\beta_3$ (income:gender interaction)**: If the coefficient is **0.00005**, this suggests that for each unit increase in `income`, the effect on the log odds of being satisfied is **greater for males** than for females (i.e., the interaction is significant).\n",
    "\n",
    "##### Standard Error (Std Err):\n",
    "- As with linear regression, the **standard error** for each coefficient shows how much variability we can expect in the estimated coefficient. A smaller standard error suggests more reliable estimates.\n",
    "\n",
    "##### z-Statistic and p-Value:\n",
    "- In logistic regression, we use the **z-statistic** to test if the coefficient is significantly different from zero.\n",
    "- A **p-value less than 0.05** indicates that the predictor is statistically significant. For example, if the p-value for `income` is **0.03**, then `income` has a significant relationship with the outcome, and we can reject the null hypothesis that the coefficient is zero.\n",
    "\n",
    "---\n",
    "\n",
    "### Example Interpretation of Output (Simplified)\n",
    "\n",
    "Let’s assume the following results from a `.summary()` table for a **logistic regression** model:\n",
    "\n",
    "| Predictor       | Coefficient ($\\beta$) | Std. Error | z-Statistic | p-Value |\n",
    "|-----------------|-----------------------|------------|-------------|---------|\n",
    "| Intercept       | -3.0                  | 0.5        | -6.0        | <0.001  |\n",
    "| income          | 0.0001                | 0.00002    | 5.0         | <0.001  |\n",
    "| gender          | 0.5                   | 0.1        | 5.0         | <0.001  |\n",
    "| income:gender   | 0.00005               | 0.00001    | 5.0         | <0.001  |\n",
    "\n",
    "- **Intercept**: The log odds of being satisfied (outcome = 1) when `income = 0` and `gender = 0` (female) is **-3.0**.\n",
    "- **income**: For every 1-unit increase in `income`, the **log odds** of being satisfied increases by **0.0001**.\n",
    "- **gender**: Being male increases the log odds of being satisfied by **0.5** compared to being female.\n",
    "- **income:gender interaction**: The effect of `income` on satisfaction is **stronger for males** by **0.00005** for each unit increase in `income`.\n",
    "\n",
    "#### Statistical Significance:\n",
    "- All the p-values are less than 0.05, meaning that **all predictors** (income, gender, and their interaction) are statistically significant. Thus, we have strong evidence that these variables influence the probability of being satisfied.\n",
    "\n",
    "---\n",
    "\n",
    "### Making Predictions Based on Statistical Evidence\n",
    "Once the model has been fitted, you can use the **coefficients** to:\n",
    "1. Make **predictions** by plugging values of predictors into the equation.\n",
    "2. Use the **p-values** to assess the strength of evidence for each predictor. If the p-value is **low** (e.g., <0.05), the predictor is considered **statistically significant**.\n",
    "3. Use the **confidence intervals** to understand the range of possible values for the coefficients and assess the precision of the estimates.\n",
    "\n",
    "\n",
    "The statistical evidence in the `.summary()` table is invaluable for understanding how each predictor influences the outcome, helping you make informed decisions about which variables matter most in your models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059e0e46",
   "metadata": {},
   "source": [
    "5.\n",
    "### Steps:\n",
    "1. **Simulate Data**: We'll create random data for a continuous variable (`income`) and a binary indicator variable (`gender`), and simulate a continuous outcome variable (`happiness_score`).\n",
    "2. **Fit Models**:\n",
    "   - **Additive Model**: Fit a linear model using just `income` and `gender`.\n",
    "   - **Interaction Model**: Fit a linear model with an interaction term between `income` and `gender`.\n",
    "3. **Visualize**: Plot the data with the fitted best-fit lines.\n",
    "\n",
    "### Interpretation of Visualizations:\n",
    "- **Additive Model**:\n",
    "  - The plot will show a best-fit line for the additive model. This line represents the relationship between `income` and `happiness_score`, assuming that `gender` doesn’t interact with `income`.\n",
    "  - The line will likely slope upwards, indicating that higher income generally leads to a higher happiness score, with a shift between genders (based on the coefficient for `gender`).\n",
    "\n",
    "- **Interaction Model**:\n",
    "  - The plot will include a best-fit line that represents the relationship between `income` and `happiness_score`, considering both the main effects of `income` and `gender`, as well as their interaction.\n",
    "  - The line will likely change its slope depending on gender (if the interaction term is significant), illustrating how the effect of income differs for males vs. females."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2f3617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Simulate data\n",
    "np.random.seed(42)\n",
    "n = 200\n",
    "income = np.random.normal(50000, 10000, n)  # Continuous variable\n",
    "gender = np.random.choice([0, 1], n)        # Binary variable: 0 = Female, 1 = Male\n",
    "\n",
    "# Simulate outcome variable (happiness_score) with some random noise\n",
    "# Additive model\n",
    "happiness_score_additive = 50 + 0.05 * income + 2 * gender + np.random.normal(0, 5, n)\n",
    "\n",
    "# Interaction model\n",
    "happiness_score_interaction = 50 + 0.05 * income + 2 * gender + 0.01 * income * gender + np.random.normal(0, 5, n)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'income': income, 'gender': gender, 'happiness_score_additive': happiness_score_additive, 'happiness_score_interaction': happiness_score_interaction})\n",
    "\n",
    "# Add constant term for the model\n",
    "X_additive = sm.add_constant(data[['income', 'gender']])\n",
    "X_interaction = sm.add_constant(data[['income', 'gender', 'income:gender']])\n",
    "\n",
    "# Fit models\n",
    "model_additive = sm.OLS(data['happiness_score_additive'], X_additive).fit()\n",
    "model_interaction = sm.OLS(data['happiness_score_interaction'], X_interaction).fit()\n",
    "\n",
    "# Get predictions\n",
    "pred_additive = model_additive.predict(X_additive)\n",
    "pred_interaction = model_interaction.predict(X_interaction)\n",
    "\n",
    "# Plotly Visualization for Additive Specification\n",
    "fig_additive = go.Figure()\n",
    "\n",
    "# Scatter plot for data\n",
    "fig_additive.add_trace(go.Scatter(x=data['income'], y=data['happiness_score_additive'], mode='markers', name='Data', marker=dict(color=data['gender'], colorscale='Viridis')))\n",
    "\n",
    "# Best fit line for Additive Model\n",
    "fig_additive.add_trace(go.Scatter(x=data['income'], y=pred_additive, mode='lines', name='Best Fit Line', line=dict(color='blue', width=2)))\n",
    "\n",
    "fig_additive.update_layout(title='Additive Model: Happiness Score vs. Income with Gender (No Interaction)',\n",
    "                           xaxis_title='Income',\n",
    "                           yaxis_title='Happiness Score',\n",
    "                           showlegend=True)\n",
    "\n",
    "# Plotly Visualization for Synergistic (Interaction) Specification\n",
    "fig_interaction = go.Figure()\n",
    "\n",
    "# Scatter plot for data\n",
    "fig_interaction.add_trace(go.Scatter(x=data['income'], y=data['happiness_score_interaction'], mode='markers', name='Data', marker=dict(color=data['gender'], colorscale='Viridis')))\n",
    "\n",
    "# Best fit line for Interaction Model\n",
    "fig_interaction.add_trace(go.Scatter(x=data['income'], y=pred_interaction, mode='lines', name='Best Fit Line', line=dict(color='red', width=2)))\n",
    "\n",
    "fig_interaction.update_layout(title='Interaction Model: Happiness Score vs. Income with Gender (Interaction)',\n",
    "                              xaxis_title='Income',\n",
    "                              yaxis_title='Happiness Score',\n",
    "                              showlegend=True)\n",
    "\n",
    "# Show plots\n",
    "fig_additive.show()\n",
    "fig_interaction.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f477a03",
   "metadata": {},
   "source": [
    "### Summary of Interactions with ChatGPT\n",
    "\n",
    "1. **Initial Data Understanding**:\n",
    "- We worked with the **Canadian Social Connection Survey (CSCS)** dataset, where you were interested in fitting regression models with a combination of continuous, binary, and categorical predictors and a continuous outcome variable.\n",
    "\n",
    "2. **Logistic vs. Linear Regression**:\n",
    "- You initially wanted to work with **logistic regression** for a binary outcome, but due to the complexity of interpreting **log odds**, we decided to treat the results as if they were from **multivariate linear regression** for easier interpretation.\n",
    "- We simulated random noise and used **linear regression** to create models with both **additive** and **synergistic (interaction)** specifications.\n",
    "\n",
    "3. **Model Specifications**:\n",
    "- **Additive Model**:\n",
    "  - A regression model using **continuous (`income`)** and **binary (`gender`)** predictors, with no interaction term.\n",
    "  \n",
    "- **Interaction Model**:\n",
    "  - A regression model including both **`income`** and **`gender`**, along with their interaction term (**`income * gender`**), to assess if the relationship between **`income`** and the outcome (**`happiness_score`**) differs by gender.\n",
    "\n",
    "4. **Visualization with Plotly**:\n",
    "- **Plotly** was used to visualize the data and the best-fit regression lines for both model specifications:\n",
    "  - **Additive model**: A simple best-fit line based on the continuous and binary predictors.\n",
    "  - **Interaction model**: A best-fit line considering both the main effects of **`income`** and **`gender`** and their interaction term.\n",
    "  \n",
    "- The visualization helped illustrate the relationship between **`income`**, **`gender`**, and the outcome (**`happiness_score`**), showing the differences in the regression lines and the potential need (or lack thereof) for the interaction term.\n",
    "\n",
    "5. **Interpretation**:\n",
    "- We discussed how to interpret **coefficients**, **standard errors**, **t-statistics**, **p-values**, and **confidence intervals** from the `.summary()` table of the models.\n",
    "- Focus was given to understanding how predictors affect the outcome, and whether the interaction term adds significant explanatory power to the model.\n",
    "\n",
    "6. **Final Insights**:\n",
    "- **Additive vs. Interaction**:\n",
    "  - By plotting the best-fit lines for both models, you were able to visually assess whether the interaction term between **`income`** and **`gender`** was necessary to improve model fit.\n",
    "  \n",
    "- **Model Simplicity**:\n",
    "  - We kept the analysis simple, treating **logistic regression** as **linear regression** for easier interpretation and visualization, given the challenges of interpreting log odds in logistic models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278631c3",
   "metadata": {},
   "source": [
    "[Chatbot transcript](https://chatgpt.com/share/6734291b-e440-800f-904e-311fec919cb6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029062c7",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29378146",
   "metadata": {},
   "source": [
    "- $R^2$ and Model Explanatory Power:\n",
    "\n",
    "    - Definition: $R^2$ represents the proportion of the variance in the outcome variable that is explained by the model’s predictors. It’s calculated by comparing the model's residual sum of squares (unexplained variability) to the total variability in the data (variance of the outcome).\n",
    "    - Interpretation: A high $R^2$ indicates that the model does a good job at capturing the variability in the outcome variable. A low $R^2$ suggests that the model, even if statistically significant, doesn’t explain much of the total variation, implying that there are likely other variables affecting the outcome that aren’t captured in this model.\n",
    "\n",
    "- p-values and Statistical Significance of Coefficients:\n",
    "\n",
    "    - Definition: p-values test the null hypothesis that a coefficient is zero (i.e., no effect). A small p-value (typically <0.05) indicates that there is strong evidence against the null hypothesis, suggesting the predictor is associated with the outcome when controlling for other variables in the model.\n",
    "    - Interpretation: Small p-values imply that the predictor variable is likely to have a statistically significant relationship with the outcome. However, this relationship is not necessarily strong in magnitude or responsible for a large portion of the variation in the outcome variable.\n",
    "\n",
    "- $R^2$ Measures Overall Fit, Not Individual Predictor Importance: $R^2$ is a summary statistic that gives an idea of how well the model as a whole captures the variability in the outcome. It’s affected by the combined explanatory power of all predictors in the model, so a low $R^2$ means that the model isn’t explaining much of the outcome’s variability, even if some individual predictors are significant.\n",
    "    - $R^2$ tells us about the model’s overall explanatory power but doesn’t speak to the reliability of individual predictors.\n",
    "    \n",
    "- p-values Assess Specific Predictor Effects, Not Overall Fit: p-values, on the other hand, tell us about the reliability of the relationship between each predictor and the outcome, controlling for the other predictors. A predictor can be statistically significant even in a model with low $R^2$, meaning it has a reliable effect on the outcome but that effect does not contribute substantially to explaining the outcome’s variability.\n",
    "    - p-values help us understand whether specific predictors reliably affect the outcome when controlling for other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db7eef77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>719</td>\n",
       "      <td>Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>719</td>\n",
       "      <td>DiancieMega Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Unbound</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Dark</td>\n",
       "      <td>80</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>170</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>721</td>\n",
       "      <td>Volcanion</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Water</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>120</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                   Name   Type 1  Type 2  HP  Attack  Defense  \\\n",
       "0      1              Bulbasaur    Grass  Poison  45      49       49   \n",
       "1      2                Ivysaur    Grass  Poison  60      62       63   \n",
       "2      3               Venusaur    Grass  Poison  80      82       83   \n",
       "3      3  VenusaurMega Venusaur    Grass  Poison  80     100      123   \n",
       "4      4             Charmander     Fire     NaN  39      52       43   \n",
       "..   ...                    ...      ...     ...  ..     ...      ...   \n",
       "795  719                Diancie     Rock   Fairy  50     100      150   \n",
       "796  719    DiancieMega Diancie     Rock   Fairy  50     160      110   \n",
       "797  720    HoopaHoopa Confined  Psychic   Ghost  80     110       60   \n",
       "798  720     HoopaHoopa Unbound  Psychic    Dark  80     160       60   \n",
       "799  721              Volcanion     Fire   Water  80     110      120   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0         65       65     45           1      False  \n",
       "1         80       80     60           1      False  \n",
       "2        100      100     80           1      False  \n",
       "3        122      120     80           1      False  \n",
       "4         60       50     65           1      False  \n",
       "..       ...      ...    ...         ...        ...  \n",
       "795      100      150     50           6       True  \n",
       "796      160      110    110           6       True  \n",
       "797      150      130     70           6       True  \n",
       "798      170      130     80           6       True  \n",
       "799      130       90     70           6       True  \n",
       "\n",
       "[800 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "# fail https://github.com/KeithGalli/pandas/blob/master/pokemon_data.csv\n",
    "pokeaman = pd.read_csv(url) \n",
    "pokeaman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "540dca3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   15.27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 11 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>3.50e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:29:53</td>     <th>  Log-Likelihood:    </th> <td> -3649.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   800</td>      <th>  AIC:               </th> <td>   7323.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   788</td>      <th>  BIC:               </th> <td>   7379.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                       <td>   26.8971</td> <td>    5.246</td> <td>    5.127</td> <td> 0.000</td> <td>   16.599</td> <td>   37.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.2]</th>              <td>   20.0449</td> <td>    7.821</td> <td>    2.563</td> <td> 0.011</td> <td>    4.692</td> <td>   35.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.3]</th>              <td>   21.3662</td> <td>    6.998</td> <td>    3.053</td> <td> 0.002</td> <td>    7.629</td> <td>   35.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.4]</th>              <td>   31.9575</td> <td>    8.235</td> <td>    3.881</td> <td> 0.000</td> <td>   15.793</td> <td>   48.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.5]</th>              <td>    9.4926</td> <td>    7.883</td> <td>    1.204</td> <td> 0.229</td> <td>   -5.982</td> <td>   24.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.6]</th>              <td>   22.2693</td> <td>    8.709</td> <td>    2.557</td> <td> 0.011</td> <td>    5.173</td> <td>   39.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                    <td>    0.5634</td> <td>    0.071</td> <td>    7.906</td> <td> 0.000</td> <td>    0.423</td> <td>    0.703</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.2]</th> <td>   -0.2350</td> <td>    0.101</td> <td>   -2.316</td> <td> 0.021</td> <td>   -0.434</td> <td>   -0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.3]</th> <td>   -0.3067</td> <td>    0.093</td> <td>   -3.300</td> <td> 0.001</td> <td>   -0.489</td> <td>   -0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.4]</th> <td>   -0.3790</td> <td>    0.105</td> <td>   -3.600</td> <td> 0.000</td> <td>   -0.586</td> <td>   -0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.5]</th> <td>   -0.0484</td> <td>    0.108</td> <td>   -0.447</td> <td> 0.655</td> <td>   -0.261</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.6]</th> <td>   -0.3083</td> <td>    0.112</td> <td>   -2.756</td> <td> 0.006</td> <td>   -0.528</td> <td>   -0.089</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>337.229</td> <th>  Durbin-Watson:     </th> <td>   1.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2871.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.684</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>11.649</td>  <th>  Cond. No.          </th> <td>1.40e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                  &        HP        & \\textbf{  R-squared:         } &     0.176   \\\\\n",
       "\\textbf{Model:}                          &       OLS        & \\textbf{  Adj. R-squared:    } &     0.164   \\\\\n",
       "\\textbf{Method:}                         &  Least Squares   & \\textbf{  F-statistic:       } &     15.27   \\\\\n",
       "\\textbf{Date:}                           & Mon, 11 Nov 2024 & \\textbf{  Prob (F-statistic):} &  3.50e-27   \\\\\n",
       "\\textbf{Time:}                           &     18:29:53     & \\textbf{  Log-Likelihood:    } &   -3649.4   \\\\\n",
       "\\textbf{No. Observations:}               &         800      & \\textbf{  AIC:               } &     7323.   \\\\\n",
       "\\textbf{Df Residuals:}                   &         788      & \\textbf{  BIC:               } &     7379.   \\\\\n",
       "\\textbf{Df Model:}                       &          11      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                         & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                       &      26.8971  &        5.246     &     5.127  &         0.000        &       16.599    &       37.195     \\\\\n",
       "\\textbf{C(Generation)[T.2]}              &      20.0449  &        7.821     &     2.563  &         0.011        &        4.692    &       35.398     \\\\\n",
       "\\textbf{C(Generation)[T.3]}              &      21.3662  &        6.998     &     3.053  &         0.002        &        7.629    &       35.103     \\\\\n",
       "\\textbf{C(Generation)[T.4]}              &      31.9575  &        8.235     &     3.881  &         0.000        &       15.793    &       48.122     \\\\\n",
       "\\textbf{C(Generation)[T.5]}              &       9.4926  &        7.883     &     1.204  &         0.229        &       -5.982    &       24.968     \\\\\n",
       "\\textbf{C(Generation)[T.6]}              &      22.2693  &        8.709     &     2.557  &         0.011        &        5.173    &       39.366     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                    &       0.5634  &        0.071     &     7.906  &         0.000        &        0.423    &        0.703     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.2]} &      -0.2350  &        0.101     &    -2.316  &         0.021        &       -0.434    &       -0.036     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.3]} &      -0.3067  &        0.093     &    -3.300  &         0.001        &       -0.489    &       -0.124     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.4]} &      -0.3790  &        0.105     &    -3.600  &         0.000        &       -0.586    &       -0.172     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.5]} &      -0.0484  &        0.108     &    -0.447  &         0.655        &       -0.261    &        0.164     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.6]} &      -0.3083  &        0.112     &    -2.756  &         0.006        &       -0.528    &       -0.089     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 337.229 & \\textbf{  Durbin-Watson:     } &    1.505  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2871.522  \\\\\n",
       "\\textbf{Skew:}          &   1.684 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  11.649 & \\textbf{  Cond. No.          } & 1.40e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.4e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.176\n",
       "Model:                            OLS   Adj. R-squared:                  0.164\n",
       "Method:                 Least Squares   F-statistic:                     15.27\n",
       "Date:                Mon, 11 Nov 2024   Prob (F-statistic):           3.50e-27\n",
       "Time:                        18:29:53   Log-Likelihood:                -3649.4\n",
       "No. Observations:                 800   AIC:                             7323.\n",
       "Df Residuals:                     788   BIC:                             7379.\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================================\n",
       "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------\n",
       "Intercept                          26.8971      5.246      5.127      0.000      16.599      37.195\n",
       "C(Generation)[T.2]                 20.0449      7.821      2.563      0.011       4.692      35.398\n",
       "C(Generation)[T.3]                 21.3662      6.998      3.053      0.002       7.629      35.103\n",
       "C(Generation)[T.4]                 31.9575      8.235      3.881      0.000      15.793      48.122\n",
       "C(Generation)[T.5]                  9.4926      7.883      1.204      0.229      -5.982      24.968\n",
       "C(Generation)[T.6]                 22.2693      8.709      2.557      0.011       5.173      39.366\n",
       "Q(\"Sp. Def\")                        0.5634      0.071      7.906      0.000       0.423       0.703\n",
       "Q(\"Sp. Def\"):C(Generation)[T.2]    -0.2350      0.101     -2.316      0.021      -0.434      -0.036\n",
       "Q(\"Sp. Def\"):C(Generation)[T.3]    -0.3067      0.093     -3.300      0.001      -0.489      -0.124\n",
       "Q(\"Sp. Def\"):C(Generation)[T.4]    -0.3790      0.105     -3.600      0.000      -0.586      -0.172\n",
       "Q(\"Sp. Def\"):C(Generation)[T.5]    -0.0484      0.108     -0.447      0.655      -0.261       0.164\n",
       "Q(\"Sp. Def\"):C(Generation)[T.6]    -0.3083      0.112     -2.756      0.006      -0.528      -0.089\n",
       "==============================================================================\n",
       "Omnibus:                      337.229   Durbin-Watson:                   1.505\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2871.522\n",
       "Skew:                           1.684   Prob(JB):                         0.00\n",
       "Kurtosis:                      11.649   Cond. No.                     1.40e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model1_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") + C(Generation)', data=pokeaman)\n",
    "model2_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") + C(Generation) + Q(\"Sp. Def\"):C(Generation)', data=pokeaman)\n",
    "model2_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") * C(Generation)', data=pokeaman)\n",
    "\n",
    "model2_fit = model2_spec.fit()\n",
    "model2_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f509a9",
   "metadata": {},
   "source": [
    "- The $R^2$ value of 0.176 indicates that this model explains about 17.6% of the variability in HP. This is relatively low, meaning that most of the variability in HP is not explained by Sp. Def or Generation and their interactions. Other factors not included in the model likely have a significant impact on HP.\n",
    "- The adjusted $R^2$ is 0.164, which accounts for the number of predictors in the model and suggests that, even with these adjustments, the model doesn’t capture much of the variability in HP.\n",
    "- The coefficient for `Q(\"Sp. Def\")` is 0.5634, with a very low p-value ($p < 0.001$). This means that Sp. Def has a statistically significant positive effect on HP. Specifically, for every one-unit increase in Sp. Def, HP increases by approximately 0.56, on average, for Generation 1 Pokémon.\n",
    "- Most of the generation indicators are statistically significant, except for Generation 5 (with $p = 0.229$). Significant coefficients for generations imply that HP tends to differ across generations even after accounting for Sp. Def.\n",
    "- The intercept is statistically significant ($p < 0.001$), meaning it’s reliably different from zero when all other predictors are zero.\n",
    "\n",
    "Conclusion:\n",
    "- The low $R^2$ (17.6%) means that Sp. Def and Generation only explain a small portion of HP’s variability, suggesting many other factors influence HP. However, the large, statistically significant coefficients indicate that Sp. Def and Generation reliably impact HP.\n",
    "- In short, a model can have significant predictors with strong effects but still a low $R^2$ if it doesn't capture most of the outcome’s variability, highlighting that Sp. Def and Generation impact HP but aren’t the main drivers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75ef8ac",
   "metadata": {},
   "source": [
    "### Summary of Interactions with ChatGPT\n",
    "\n",
    "\n",
    "We examined the apparent contradiction between a low $R^2$ (17.6%) and the presence of large, statistically significant coefficients in a regression model predicting **HP** based on **Sp. Def** and **Generation**.\n",
    "\n",
    "#### Key Points:\n",
    "\n",
    "- **Low $R^2$**: The model explains only a small portion of **HP**’s variability, meaning many other factors likely influence **HP** beyond **Sp. Def** and **Generation**.\n",
    "- **Significant Coefficients**: The large and statistically significant coefficients for **Sp. Def**, **Generation**, and their interactions show that these predictors have a meaningful and reliable effect on **HP**.\n",
    "- **Interpretation**: The combination of a low $R^2$ with significant predictors indicates that **Sp. Def** and **Generation** impact **HP** but aren’t the primary determinants of its variability.\n",
    "\n",
    "#### Conclusion:\n",
    "\n",
    "\n",
    "$R^2$ reflects the overall model fit, while significant coefficients reflect the specific effects of predictors, and both can coexist without contradiction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639e6f09",
   "metadata": {},
   "source": [
    "[Chatbot transcript](https://chatgpt.com/share/67324f4e-3954-800f-902d-ddcd75bc089a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b79957",
   "metadata": {},
   "source": [
    "# \"Post-lecture\" HW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85baa3a8",
   "metadata": {},
   "source": [
    "## Question 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bda1cdb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>338</td>\n",
       "      <td>Solrock</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>70</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Charizard</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Flying</td>\n",
       "      <td>78</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>109</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>224</td>\n",
       "      <td>Octillery</td>\n",
       "      <td>Water</td>\n",
       "      <td>None</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>600</td>\n",
       "      <td>Klang</td>\n",
       "      <td>Steel</td>\n",
       "      <td>None</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>265</td>\n",
       "      <td>Wurmple</td>\n",
       "      <td>Bug</td>\n",
       "      <td>None</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>471</td>\n",
       "      <td>Glaceon</td>\n",
       "      <td>Ice</td>\n",
       "      <td>None</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>130</td>\n",
       "      <td>95</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>225</td>\n",
       "      <td>Delibird</td>\n",
       "      <td>Ice</td>\n",
       "      <td>Flying</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>109</td>\n",
       "      <td>Koffing</td>\n",
       "      <td>Poison</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>373</td>\n",
       "      <td>SalamenceMega Salamence</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>Flying</td>\n",
       "      <td>95</td>\n",
       "      <td>145</td>\n",
       "      <td>130</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                     Name   Type 1   Type 2  HP  Attack  Defense  \\\n",
       "370  338                  Solrock     Rock  Psychic  70      95       85   \n",
       "6      6                Charizard     Fire   Flying  78      84       78   \n",
       "242  224                Octillery    Water     None  75     105       75   \n",
       "661  600                    Klang    Steel     None  60      80       95   \n",
       "288  265                  Wurmple      Bug     None  45      45       35   \n",
       "..   ...                      ...      ...      ...  ..     ...      ...   \n",
       "522  471                  Glaceon      Ice     None  65      60      110   \n",
       "243  225                 Delibird      Ice   Flying  45      55       45   \n",
       "797  720      HoopaHoopa Confined  Psychic    Ghost  80     110       60   \n",
       "117  109                  Koffing   Poison     None  40      65       95   \n",
       "409  373  SalamenceMega Salamence   Dragon   Flying  95     145      130   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "370       55       65     70           3      False  \n",
       "6        109       85    100           1      False  \n",
       "242      105       75     45           2      False  \n",
       "661       70       85     50           5      False  \n",
       "288       20       30     20           3      False  \n",
       "..       ...      ...    ...         ...        ...  \n",
       "522      130       95     65           4      False  \n",
       "243       65       45     75           2      False  \n",
       "797      150      130     70           6       True  \n",
       "117       60       45     35           1      False  \n",
       "409      120       90    120           3      False  \n",
       "\n",
       "[400 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np  # Importing numpy for numerical operations\n",
    "from sklearn.model_selection import train_test_split  # Importing train_test_split to split the data into train and test sets\n",
    "\n",
    "fifty_fifty_split_size = int(pokeaman.shape[0]*0.5)  # Calculate 50% of the total number of rows in the dataset\n",
    "\n",
    "# Replace \"NaN\" (in the \"Type 2\" column) with the string \"None\"\n",
    "pokeaman.fillna('None', inplace=True)  # Replaces missing (NaN) values with 'None' in the DataFrame\n",
    "\n",
    "np.random.seed(130)  # Set a random seed for reproducibility of the random operations (e.g., splitting the data)\n",
    "\n",
    "# Split the data into training and testing sets, with 50% for training and the rest for testing\n",
    "pokeaman_train, pokeaman_test = train_test_split(pokeaman, train_size=fifty_fifty_split_size)\n",
    "\n",
    "pokeaman_train  # Output the training set (50% of the original data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058bba2d",
   "metadata": {},
   "source": [
    "- This outputs the training set, which is a DataFrame containing 50% of the rows from the original pokeaman dataset after handling missing data and applying the random split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "361eb139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 11 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:43:43</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   42.5882</td> <td>    3.580</td> <td>   11.897</td> <td> 0.000</td> <td>   35.551</td> <td>   49.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>    <td>    0.2472</td> <td>    0.041</td> <td>    6.051</td> <td> 0.000</td> <td>    0.167</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>   <td>    0.1001</td> <td>    0.045</td> <td>    2.201</td> <td> 0.028</td> <td>    0.011</td> <td>    0.190</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    343.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}             & Mon, 11 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}             &     18:43:43     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:} &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}     &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      42.5882  &        3.580     &    11.897  &         0.000        &       35.551    &       49.626     \\\\\n",
       "\\textbf{Attack}    &       0.2472  &        0.041     &     6.051  &         0.000        &        0.167    &        0.327     \\\\\n",
       "\\textbf{Defense}   &       0.1001  &        0.045     &     2.201  &         0.028        &        0.011    &        0.190     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     343.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Mon, 11 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        18:43:43   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     42.5882      3.580     11.897      0.000      35.551      49.626\n",
       "Attack         0.2472      0.041      6.051      0.000       0.167       0.327\n",
       "Defense        0.1001      0.045      2.201      0.028       0.011       0.190\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         343.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spec3 = smf.ols(formula='HP ~ Attack + Defense',  # Specify the OLS (Ordinary Least Squares) regression model with 'HP' as the dependent variable and 'Attack' and 'Defense' as independent variables\n",
    "                      data=pokeaman_train)  # The model uses 'pokeaman_train' dataset\n",
    "\n",
    "model3_fit = model_spec3.fit()  # Fit the model to the training data and store the results in 'model3_fit'\n",
    "\n",
    "model3_fit.summary()  # Output a summary of the model fit, including coefficients, R-squared value, p-values, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1582a1",
   "metadata": {},
   "source": [
    "This outputs a detailed summary of the fitted model, providing key statistics like the coefficients, R-squared, and p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ef5d0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.14771558304519894\n",
      "'Out of sample' R-squared: 0.21208501873920738\n"
     ]
    }
   ],
   "source": [
    "yhat_model3 = model3_fit.predict(pokeaman_test)  # Use the fitted model to predict 'HP' values for the test data (pokeaman_test)\n",
    "\n",
    "y = pokeaman_test.HP  # Store the true 'HP' values from the test data in variable 'y'\n",
    "\n",
    "print(\"'In sample' R-squared:    \", model3_fit.rsquared)  # Output the R-squared value for the training data (in-sample performance)\n",
    "\n",
    "# Calculate and output the R-squared value for the test data (out-of-sample performance) by computing the correlation coefficient between true and predicted values\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y, yhat_model3)[0, 1]**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6ca1c3",
   "metadata": {},
   "source": [
    "This code calculates both the in-sample R-squared (on the training data) and the out-of-sample R-squared (on the test data) to evaluate the performance of the linear regression model. The in-sample R-squared measures how well the model fits the training data, while the out-of-sample R-squared evaluates how well the model predicts on unseen test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5dc92d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 11 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>4.23e-21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:45:09</td>     <th>  Log-Likelihood:    </th> <td> -1738.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3603.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   337</td>      <th>  BIC:               </th> <td>   3855.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    62</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                  <td></td>                                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                        <td>  521.5715</td> <td>  130.273</td> <td>    4.004</td> <td> 0.000</td> <td>  265.322</td> <td>  777.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]</th>                                                <td>   -6.1179</td> <td>    2.846</td> <td>   -2.150</td> <td> 0.032</td> <td>  -11.716</td> <td>   -0.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                                                           <td>   -8.1938</td> <td>    2.329</td> <td>   -3.518</td> <td> 0.000</td> <td>  -12.775</td> <td>   -3.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]</th>                                         <td>-1224.9610</td> <td>  545.105</td> <td>   -2.247</td> <td> 0.025</td> <td>-2297.199</td> <td> -152.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>                                                          <td>   -6.1989</td> <td>    2.174</td> <td>   -2.851</td> <td> 0.005</td> <td>  -10.475</td> <td>   -1.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]</th>                                        <td> -102.4030</td> <td>   96.565</td> <td>   -1.060</td> <td> 0.290</td> <td> -292.350</td> <td>   87.544</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense</th>                                                   <td>    0.0985</td> <td>    0.033</td> <td>    2.982</td> <td> 0.003</td> <td>    0.034</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]</th>                                 <td>   14.6361</td> <td>    6.267</td> <td>    2.336</td> <td> 0.020</td> <td>    2.310</td> <td>   26.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                                                            <td>   -7.2261</td> <td>    2.178</td> <td>   -3.318</td> <td> 0.001</td> <td>  -11.511</td> <td>   -2.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]</th>                                          <td>  704.8798</td> <td>  337.855</td> <td>    2.086</td> <td> 0.038</td> <td>   40.309</td> <td> 1369.450</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed</th>                                                     <td>    0.1264</td> <td>    0.038</td> <td>    3.351</td> <td> 0.001</td> <td>    0.052</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]</th>                                   <td>    5.8648</td> <td>    2.692</td> <td>    2.179</td> <td> 0.030</td> <td>    0.570</td> <td>   11.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed</th>                                                    <td>    0.1026</td> <td>    0.039</td> <td>    2.634</td> <td> 0.009</td> <td>    0.026</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]</th>                                  <td>   -6.9266</td> <td>    3.465</td> <td>   -1.999</td> <td> 0.046</td> <td>  -13.742</td> <td>   -0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed</th>                                             <td>   -0.0016</td> <td>    0.001</td> <td>   -2.837</td> <td> 0.005</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]</th>                           <td>   -0.0743</td> <td>    0.030</td> <td>   -2.477</td> <td> 0.014</td> <td>   -0.133</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                                                     <td>   -5.3982</td> <td>    1.938</td> <td>   -2.785</td> <td> 0.006</td> <td>   -9.211</td> <td>   -1.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Def\")</th>                                   <td> -282.2496</td> <td>  126.835</td> <td>   -2.225</td> <td> 0.027</td> <td> -531.738</td> <td>  -32.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\")</th>                                              <td>    0.1094</td> <td>    0.034</td> <td>    3.233</td> <td> 0.001</td> <td>    0.043</td> <td>    0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Def\")</th>                            <td>   12.6503</td> <td>    5.851</td> <td>    2.162</td> <td> 0.031</td> <td>    1.141</td> <td>   24.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Def\")</th>                                             <td>    0.0628</td> <td>    0.028</td> <td>    2.247</td> <td> 0.025</td> <td>    0.008</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Def\")</th>                           <td>    3.3949</td> <td>    1.783</td> <td>    1.904</td> <td> 0.058</td> <td>   -0.112</td> <td>    6.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Def\")</th>                                      <td>   -0.0012</td> <td>    0.000</td> <td>   -2.730</td> <td> 0.007</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")</th>                    <td>   -0.1456</td> <td>    0.065</td> <td>   -2.253</td> <td> 0.025</td> <td>   -0.273</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\")</th>                                               <td>    0.0624</td> <td>    0.031</td> <td>    2.027</td> <td> 0.043</td> <td>    0.002</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                             <td>   -3.2219</td> <td>    1.983</td> <td>   -1.625</td> <td> 0.105</td> <td>   -7.122</td> <td>    0.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\")</th>                                        <td>   -0.0014</td> <td>    0.001</td> <td>   -2.732</td> <td> 0.007</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                      <td>   -0.0695</td> <td>    0.033</td> <td>   -2.100</td> <td> 0.036</td> <td>   -0.135</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Def\")</th>                                       <td>   -0.0008</td> <td>    0.000</td> <td>   -1.743</td> <td> 0.082</td> <td>   -0.002</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                     <td>    0.0334</td> <td>    0.021</td> <td>    1.569</td> <td> 0.117</td> <td>   -0.008</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Def\")</th>                                <td> 1.629e-05</td> <td> 6.92e-06</td> <td>    2.355</td> <td> 0.019</td> <td> 2.68e-06</td> <td> 2.99e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>              <td>    0.0008</td> <td>    0.000</td> <td>    2.433</td> <td> 0.015</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                                                     <td>   -8.3636</td> <td>    2.346</td> <td>   -3.565</td> <td> 0.000</td> <td>  -12.978</td> <td>   -3.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Atk\")</th>                                   <td>  850.5436</td> <td>  385.064</td> <td>    2.209</td> <td> 0.028</td> <td>   93.112</td> <td> 1607.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Atk\")</th>                                              <td>    0.1388</td> <td>    0.040</td> <td>    3.500</td> <td> 0.001</td> <td>    0.061</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Atk\")</th>                            <td>    2.1809</td> <td>    1.136</td> <td>    1.920</td> <td> 0.056</td> <td>   -0.054</td> <td>    4.416</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Atk\")</th>                                             <td>    0.0831</td> <td>    0.038</td> <td>    2.162</td> <td> 0.031</td> <td>    0.007</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Atk\")</th>                           <td>   -7.3121</td> <td>    3.376</td> <td>   -2.166</td> <td> 0.031</td> <td>  -13.953</td> <td>   -0.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Atk\")</th>                                      <td>   -0.0014</td> <td>    0.001</td> <td>   -2.480</td> <td> 0.014</td> <td>   -0.003</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")</th>                    <td>   -0.0434</td> <td>    0.022</td> <td>   -2.010</td> <td> 0.045</td> <td>   -0.086</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Atk\")</th>                                               <td>    0.1011</td> <td>    0.035</td> <td>    2.872</td> <td> 0.004</td> <td>    0.032</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                             <td>  -12.6343</td> <td>    5.613</td> <td>   -2.251</td> <td> 0.025</td> <td>  -23.674</td> <td>   -1.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Atk\")</th>                                        <td>   -0.0018</td> <td>    0.001</td> <td>   -3.102</td> <td> 0.002</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                      <td>    0.0151</td> <td>    0.009</td> <td>    1.609</td> <td> 0.109</td> <td>   -0.003</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Atk\")</th>                                       <td>   -0.0012</td> <td>    0.001</td> <td>   -1.860</td> <td> 0.064</td> <td>   -0.002</td> <td> 6.62e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                     <td>    0.1210</td> <td>    0.054</td> <td>    2.260</td> <td> 0.024</td> <td>    0.016</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Atk\")</th>                                <td> 2.125e-05</td> <td>  9.1e-06</td> <td>    2.334</td> <td> 0.020</td> <td> 3.34e-06</td> <td> 3.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>              <td> 6.438e-06</td> <td> 7.69e-05</td> <td>    0.084</td> <td> 0.933</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                        <td>    0.1265</td> <td>    0.033</td> <td>    3.821</td> <td> 0.000</td> <td>    0.061</td> <td>    0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                      <td>   -5.0544</td> <td>    2.506</td> <td>   -2.017</td> <td> 0.044</td> <td>   -9.983</td> <td>   -0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                 <td>   -0.0021</td> <td>    0.001</td> <td>   -3.606</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>               <td>   -0.0346</td> <td>    0.017</td> <td>   -1.992</td> <td> 0.047</td> <td>   -0.069</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                <td>   -0.0012</td> <td>    0.000</td> <td>   -2.406</td> <td> 0.017</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>              <td>    0.0446</td> <td>    0.025</td> <td>    1.794</td> <td> 0.074</td> <td>   -0.004</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                         <td> 1.973e-05</td> <td> 7.28e-06</td> <td>    2.710</td> <td> 0.007</td> <td> 5.41e-06</td> <td>  3.4e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>       <td>    0.0005</td> <td>    0.000</td> <td>    1.957</td> <td> 0.051</td> <td>-2.56e-06</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                  <td>   -0.0013</td> <td>    0.000</td> <td>   -2.740</td> <td> 0.006</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                <td>    0.0841</td> <td>    0.040</td> <td>    2.125</td> <td> 0.034</td> <td>    0.006</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                           <td> 2.379e-05</td> <td> 7.85e-06</td> <td>    3.030</td> <td> 0.003</td> <td> 8.34e-06</td> <td> 3.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>         <td> 2.864e-05</td> <td> 7.73e-05</td> <td>    0.370</td> <td> 0.711</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                          <td> 1.284e-05</td> <td> 7.46e-06</td> <td>    1.721</td> <td> 0.086</td> <td>-1.83e-06</td> <td> 2.75e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>        <td>   -0.0008</td> <td>    0.000</td> <td>   -2.085</td> <td> 0.038</td> <td>   -0.002</td> <td>-4.68e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                   <td> -2.53e-07</td> <td>  1.1e-07</td> <td>   -2.292</td> <td> 0.023</td> <td> -4.7e-07</td> <td>-3.59e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th> <td>-1.425e-06</td> <td> 1.14e-06</td> <td>   -1.249</td> <td> 0.212</td> <td>-3.67e-06</td> <td> 8.19e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.20e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.2e+16. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                                                   &        HP        & \\textbf{  R-squared:         } &     0.467   \\\\\n",
       "\\textbf{Model:}                                                           &       OLS        & \\textbf{  Adj. R-squared:    } &     0.369   \\\\\n",
       "\\textbf{Method:}                                                          &  Least Squares   & \\textbf{  F-statistic:       } &     4.764   \\\\\n",
       "\\textbf{Date:}                                                            & Mon, 11 Nov 2024 & \\textbf{  Prob (F-statistic):} &  4.23e-21   \\\\\n",
       "\\textbf{Time:}                                                            &     18:45:09     & \\textbf{  Log-Likelihood:    } &   -1738.6   \\\\\n",
       "\\textbf{No. Observations:}                                                &         400      & \\textbf{  AIC:               } &     3603.   \\\\\n",
       "\\textbf{Df Residuals:}                                                    &         337      & \\textbf{  BIC:               } &     3855.   \\\\\n",
       "\\textbf{Df Model:}                                                        &          62      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                                                 &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                                          & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                                        &     521.5715  &      130.273     &     4.004  &         0.000        &      265.322    &      777.821     \\\\\n",
       "\\textbf{Legendary[T.True]}                                                &      -6.1179  &        2.846     &    -2.150  &         0.032        &      -11.716    &       -0.520     \\\\\n",
       "\\textbf{Attack}                                                           &      -8.1938  &        2.329     &    -3.518  &         0.000        &      -12.775    &       -3.612     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]}                                         &   -1224.9610  &      545.105     &    -2.247  &         0.025        &    -2297.199    &     -152.723     \\\\\n",
       "\\textbf{Defense}                                                          &      -6.1989  &        2.174     &    -2.851  &         0.005        &      -10.475    &       -1.923     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]}                                        &    -102.4030  &       96.565     &    -1.060  &         0.290        &     -292.350    &       87.544     \\\\\n",
       "\\textbf{Attack:Defense}                                                   &       0.0985  &        0.033     &     2.982  &         0.003        &        0.034    &        0.164     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]}                                 &      14.6361  &        6.267     &     2.336  &         0.020        &        2.310    &       26.963     \\\\\n",
       "\\textbf{Speed}                                                            &      -7.2261  &        2.178     &    -3.318  &         0.001        &      -11.511    &       -2.942     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]}                                          &     704.8798  &      337.855     &     2.086  &         0.038        &       40.309    &     1369.450     \\\\\n",
       "\\textbf{Attack:Speed}                                                     &       0.1264  &        0.038     &     3.351  &         0.001        &        0.052    &        0.201     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]}                                   &       5.8648  &        2.692     &     2.179  &         0.030        &        0.570    &       11.160     \\\\\n",
       "\\textbf{Defense:Speed}                                                    &       0.1026  &        0.039     &     2.634  &         0.009        &        0.026    &        0.179     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]}                                  &      -6.9266  &        3.465     &    -1.999  &         0.046        &      -13.742    &       -0.111     \\\\\n",
       "\\textbf{Attack:Defense:Speed}                                             &      -0.0016  &        0.001     &    -2.837  &         0.005        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]}                           &      -0.0743  &        0.030     &    -2.477  &         0.014        &       -0.133    &       -0.015     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                                                     &      -5.3982  &        1.938     &    -2.785  &         0.006        &       -9.211    &       -1.586     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Def\")}                                   &    -282.2496  &      126.835     &    -2.225  &         0.027        &     -531.738    &      -32.761     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\")}                                              &       0.1094  &        0.034     &     3.233  &         0.001        &        0.043    &        0.176     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Def\")}                            &      12.6503  &        5.851     &     2.162  &         0.031        &        1.141    &       24.160     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Def\")}                                             &       0.0628  &        0.028     &     2.247  &         0.025        &        0.008    &        0.118     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Def\")}                           &       3.3949  &        1.783     &     1.904  &         0.058        &       -0.112    &        6.902     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Def\")}                                      &      -0.0012  &        0.000     &    -2.730  &         0.007        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")}                    &      -0.1456  &        0.065     &    -2.253  &         0.025        &       -0.273    &       -0.018     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\")}                                               &       0.0624  &        0.031     &     2.027  &         0.043        &        0.002    &        0.123     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Def\")}                             &      -3.2219  &        1.983     &    -1.625  &         0.105        &       -7.122    &        0.678     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\")}                                        &      -0.0014  &        0.001     &    -2.732  &         0.007        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")}                      &      -0.0695  &        0.033     &    -2.100  &         0.036        &       -0.135    &       -0.004     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Def\")}                                       &      -0.0008  &        0.000     &    -1.743  &         0.082        &       -0.002    &        0.000     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")}                     &       0.0334  &        0.021     &     1.569  &         0.117        &       -0.008    &        0.075     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Def\")}                                &    1.629e-05  &     6.92e-06     &     2.355  &         0.019        &     2.68e-06    &     2.99e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")}              &       0.0008  &        0.000     &     2.433  &         0.015        &        0.000    &        0.001     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                                                     &      -8.3636  &        2.346     &    -3.565  &         0.000        &      -12.978    &       -3.749     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Atk\")}                                   &     850.5436  &      385.064     &     2.209  &         0.028        &       93.112    &     1607.975     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Atk\")}                                              &       0.1388  &        0.040     &     3.500  &         0.001        &        0.061    &        0.217     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Atk\")}                            &       2.1809  &        1.136     &     1.920  &         0.056        &       -0.054    &        4.416     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Atk\")}                                             &       0.0831  &        0.038     &     2.162  &         0.031        &        0.007    &        0.159     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Atk\")}                           &      -7.3121  &        3.376     &    -2.166  &         0.031        &      -13.953    &       -0.671     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Atk\")}                                      &      -0.0014  &        0.001     &    -2.480  &         0.014        &       -0.003    &       -0.000     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")}                    &      -0.0434  &        0.022     &    -2.010  &         0.045        &       -0.086    &       -0.001     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Atk\")}                                               &       0.1011  &        0.035     &     2.872  &         0.004        &        0.032    &        0.170     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                             &     -12.6343  &        5.613     &    -2.251  &         0.025        &      -23.674    &       -1.594     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Atk\")}                                        &      -0.0018  &        0.001     &    -3.102  &         0.002        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                      &       0.0151  &        0.009     &     1.609  &         0.109        &       -0.003    &        0.034     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Atk\")}                                       &      -0.0012  &        0.001     &    -1.860  &         0.064        &       -0.002    &     6.62e-05     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                     &       0.1210  &        0.054     &     2.260  &         0.024        &        0.016    &        0.226     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Atk\")}                                &    2.125e-05  &      9.1e-06     &     2.334  &         0.020        &     3.34e-06    &     3.92e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}              &    6.438e-06  &     7.69e-05     &     0.084  &         0.933        &       -0.000    &        0.000     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                        &       0.1265  &        0.033     &     3.821  &         0.000        &        0.061    &        0.192     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                      &      -5.0544  &        2.506     &    -2.017  &         0.044        &       -9.983    &       -0.126     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                 &      -0.0021  &        0.001     &    -3.606  &         0.000        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}               &      -0.0346  &        0.017     &    -1.992  &         0.047        &       -0.069    &       -0.000     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                &      -0.0012  &        0.000     &    -2.406  &         0.017        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}              &       0.0446  &        0.025     &     1.794  &         0.074        &       -0.004    &        0.093     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                         &    1.973e-05  &     7.28e-06     &     2.710  &         0.007        &     5.41e-06    &      3.4e-05     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}       &       0.0005  &        0.000     &     1.957  &         0.051        &    -2.56e-06    &        0.001     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                  &      -0.0013  &        0.000     &    -2.740  &         0.006        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                &       0.0841  &        0.040     &     2.125  &         0.034        &        0.006    &        0.162     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                           &    2.379e-05  &     7.85e-06     &     3.030  &         0.003        &     8.34e-06    &     3.92e-05     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}         &    2.864e-05  &     7.73e-05     &     0.370  &         0.711        &       -0.000    &        0.000     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                          &    1.284e-05  &     7.46e-06     &     1.721  &         0.086        &    -1.83e-06    &     2.75e-05     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}        &      -0.0008  &        0.000     &    -2.085  &         0.038        &       -0.002    &    -4.68e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                   &    -2.53e-07  &      1.1e-07     &    -2.292  &         0.023        &     -4.7e-07    &    -3.59e-08     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")} &   -1.425e-06  &     1.14e-06     &    -1.249  &         0.212        &    -3.67e-06    &     8.19e-07     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.664  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.20e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.2e+16. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.467\n",
       "Model:                            OLS   Adj. R-squared:                  0.369\n",
       "Method:                 Least Squares   F-statistic:                     4.764\n",
       "Date:                Mon, 11 Nov 2024   Prob (F-statistic):           4.23e-21\n",
       "Time:                        18:45:09   Log-Likelihood:                -1738.6\n",
       "No. Observations:                 400   AIC:                             3603.\n",
       "Df Residuals:                     337   BIC:                             3855.\n",
       "Df Model:                          62                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================================================================\n",
       "                                                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                          521.5715    130.273      4.004      0.000     265.322     777.821\n",
       "Legendary[T.True]                                                   -6.1179      2.846     -2.150      0.032     -11.716      -0.520\n",
       "Attack                                                              -8.1938      2.329     -3.518      0.000     -12.775      -3.612\n",
       "Attack:Legendary[T.True]                                         -1224.9610    545.105     -2.247      0.025   -2297.199    -152.723\n",
       "Defense                                                             -6.1989      2.174     -2.851      0.005     -10.475      -1.923\n",
       "Defense:Legendary[T.True]                                         -102.4030     96.565     -1.060      0.290    -292.350      87.544\n",
       "Attack:Defense                                                       0.0985      0.033      2.982      0.003       0.034       0.164\n",
       "Attack:Defense:Legendary[T.True]                                    14.6361      6.267      2.336      0.020       2.310      26.963\n",
       "Speed                                                               -7.2261      2.178     -3.318      0.001     -11.511      -2.942\n",
       "Speed:Legendary[T.True]                                            704.8798    337.855      2.086      0.038      40.309    1369.450\n",
       "Attack:Speed                                                         0.1264      0.038      3.351      0.001       0.052       0.201\n",
       "Attack:Speed:Legendary[T.True]                                       5.8648      2.692      2.179      0.030       0.570      11.160\n",
       "Defense:Speed                                                        0.1026      0.039      2.634      0.009       0.026       0.179\n",
       "Defense:Speed:Legendary[T.True]                                     -6.9266      3.465     -1.999      0.046     -13.742      -0.111\n",
       "Attack:Defense:Speed                                                -0.0016      0.001     -2.837      0.005      -0.003      -0.001\n",
       "Attack:Defense:Speed:Legendary[T.True]                              -0.0743      0.030     -2.477      0.014      -0.133      -0.015\n",
       "Q(\"Sp. Def\")                                                        -5.3982      1.938     -2.785      0.006      -9.211      -1.586\n",
       "Legendary[T.True]:Q(\"Sp. Def\")                                    -282.2496    126.835     -2.225      0.027    -531.738     -32.761\n",
       "Attack:Q(\"Sp. Def\")                                                  0.1094      0.034      3.233      0.001       0.043       0.176\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Def\")                               12.6503      5.851      2.162      0.031       1.141      24.160\n",
       "Defense:Q(\"Sp. Def\")                                                 0.0628      0.028      2.247      0.025       0.008       0.118\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Def\")                               3.3949      1.783      1.904      0.058      -0.112       6.902\n",
       "Attack:Defense:Q(\"Sp. Def\")                                         -0.0012      0.000     -2.730      0.007      -0.002      -0.000\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")                       -0.1456      0.065     -2.253      0.025      -0.273      -0.018\n",
       "Speed:Q(\"Sp. Def\")                                                   0.0624      0.031      2.027      0.043       0.002       0.123\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Def\")                                -3.2219      1.983     -1.625      0.105      -7.122       0.678\n",
       "Attack:Speed:Q(\"Sp. Def\")                                           -0.0014      0.001     -2.732      0.007      -0.002      -0.000\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")                         -0.0695      0.033     -2.100      0.036      -0.135      -0.004\n",
       "Defense:Speed:Q(\"Sp. Def\")                                          -0.0008      0.000     -1.743      0.082      -0.002       0.000\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")                         0.0334      0.021      1.569      0.117      -0.008       0.075\n",
       "Attack:Defense:Speed:Q(\"Sp. Def\")                                 1.629e-05   6.92e-06      2.355      0.019    2.68e-06    2.99e-05\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")                  0.0008      0.000      2.433      0.015       0.000       0.001\n",
       "Q(\"Sp. Atk\")                                                        -8.3636      2.346     -3.565      0.000     -12.978      -3.749\n",
       "Legendary[T.True]:Q(\"Sp. Atk\")                                     850.5436    385.064      2.209      0.028      93.112    1607.975\n",
       "Attack:Q(\"Sp. Atk\")                                                  0.1388      0.040      3.500      0.001       0.061       0.217\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Atk\")                                2.1809      1.136      1.920      0.056      -0.054       4.416\n",
       "Defense:Q(\"Sp. Atk\")                                                 0.0831      0.038      2.162      0.031       0.007       0.159\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Atk\")                              -7.3121      3.376     -2.166      0.031     -13.953      -0.671\n",
       "Attack:Defense:Q(\"Sp. Atk\")                                         -0.0014      0.001     -2.480      0.014      -0.003      -0.000\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")                       -0.0434      0.022     -2.010      0.045      -0.086      -0.001\n",
       "Speed:Q(\"Sp. Atk\")                                                   0.1011      0.035      2.872      0.004       0.032       0.170\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Atk\")                               -12.6343      5.613     -2.251      0.025     -23.674      -1.594\n",
       "Attack:Speed:Q(\"Sp. Atk\")                                           -0.0018      0.001     -3.102      0.002      -0.003      -0.001\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")                          0.0151      0.009      1.609      0.109      -0.003       0.034\n",
       "Defense:Speed:Q(\"Sp. Atk\")                                          -0.0012      0.001     -1.860      0.064      -0.002    6.62e-05\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")                         0.1210      0.054      2.260      0.024       0.016       0.226\n",
       "Attack:Defense:Speed:Q(\"Sp. Atk\")                                 2.125e-05    9.1e-06      2.334      0.020    3.34e-06    3.92e-05\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")               6.438e-06   7.69e-05      0.084      0.933      -0.000       0.000\n",
       "Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                            0.1265      0.033      3.821      0.000       0.061       0.192\n",
       "Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                         -5.0544      2.506     -2.017      0.044      -9.983      -0.126\n",
       "Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                    -0.0021      0.001     -3.606      0.000      -0.003      -0.001\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  -0.0346      0.017     -1.992      0.047      -0.069      -0.000\n",
       "Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                   -0.0012      0.000     -2.406      0.017      -0.002      -0.000\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  0.0446      0.025      1.794      0.074      -0.004       0.093\n",
       "Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                          1.973e-05   7.28e-06      2.710      0.007    5.41e-06     3.4e-05\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           0.0005      0.000      1.957      0.051   -2.56e-06       0.001\n",
       "Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                     -0.0013      0.000     -2.740      0.006      -0.002      -0.000\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                    0.0841      0.040      2.125      0.034       0.006       0.162\n",
       "Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                            2.379e-05   7.85e-06      3.030      0.003    8.34e-06    3.92e-05\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")          2.864e-05   7.73e-05      0.370      0.711      -0.000       0.000\n",
       "Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                           1.284e-05   7.46e-06      1.721      0.086   -1.83e-06    2.75e-05\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           -0.0008      0.000     -2.085      0.038      -0.002   -4.68e-05\n",
       "Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                    -2.53e-07    1.1e-07     -2.292      0.023    -4.7e-07   -3.59e-08\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\") -1.425e-06   1.14e-06     -1.249      0.212   -3.67e-06    8.19e-07\n",
       "==============================================================================\n",
       "Omnibus:                      214.307   Durbin-Watson:                   1.992\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2354.664\n",
       "Skew:                           2.026   Prob(JB):                         0.00\n",
       "Kurtosis:                      14.174   Cond. No.                     1.20e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.2e+16. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_linear_form = 'HP ~ Attack * Defense * Speed * Legendary'  # Define the formula for the OLS regression model, including main effects and interactions between Attack, Defense, Speed, and Legendary\n",
    "\n",
    "model4_linear_form += ' * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'  # Add interactions with \"Sp. Def\" and \"Sp. Atk\" (using Q() to correctly interpret special characters in column names)\n",
    "\n",
    "# DO NOT try adding '* C(Generation) * C(Q(\"Type 1\")) * C(Q(\"Type 2\"))'\n",
    "# This comment warns about adding too many interaction terms, as it would result in an unmanageable number of combinations (6*18*19 possible interactions), which could overwhelm your computer\n",
    "\n",
    "model4_spec = smf.ols(formula=model4_linear_form, data=pokeaman_train)  # Specify the OLS regression model with the interactions defined above, using the 'pokeaman_train' dataset\n",
    "\n",
    "model4_fit = model4_spec.fit()  # Fit the model to the training data and store the results in 'model4_fit'\n",
    "\n",
    "model4_fit.summary()  # Output a summary of the model fit, including coefficients, interaction terms, and other statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db69b8b",
   "metadata": {},
   "source": [
    "This code defines and fits a complex regression model with many interaction terms, trying to predict HP using multiple features (main effects and interactions) from the pokeaman_train dataset. The model includes interactions between several attributes of Pokémon, such as Attack, Defense, Speed, and Legendary status, and adds even more interactions with special stats like Sp. Def and Sp. Atk. The model summary will provide a comprehensive overview of the fit, allowing for assessment of the significance of each term and the overall model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07f81274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.46709442115833855\n",
      "'Out of sample' R-squared: 0.002485342598992873\n"
     ]
    }
   ],
   "source": [
    "yhat_model4 = model4_fit.predict(pokeaman_test)  # Use the fitted model to predict 'HP' values for the test data (pokeaman_test)\n",
    "\n",
    "y = pokeaman_test.HP  # Store the true 'HP' values from the test data in variable 'y'\n",
    "\n",
    "print(\"'In sample' R-squared:    \", model4_fit.rsquared)  # Output the R-squared value for the training data (in-sample performance)\n",
    "\n",
    "# Calculate and output the R-squared value for the test data (out-of-sample performance) by computing the correlation coefficient between true and predicted values\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y, yhat_model4)[0, 1]**2)  # Calculate the out-of-sample R-squared by squaring the correlation coefficient between true and predicted values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8efad67",
   "metadata": {},
   "source": [
    "The code calculates both the in-sample R-squared (on the training data) and the out-of-sample R-squared (on the test data). The in-sample R-squared shows how well the model fits the training data, while the out-of-sample R-squared assesses the model's ability to predict HP values on unseen data, providing an evaluation of the model's generalizability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504b2d97",
   "metadata": {},
   "source": [
    "### Summary of Interactions with ChatGPT\n",
    "\n",
    "1. **Data Analysis and Model Building**:\n",
    "   - You are working on analyzing Pokémon data (`pokeaman` dataset) and building various regression models to predict the `$HP$` variable using other features like `$Attack$`, `$Defense$`, `$Speed$`, `$Legendary$`, and special stats such as `$Sp. Def$` and `$Sp. Atk$`.\n",
    "   - We discussed how to perform basic data preparation (handling missing values, splitting data) and building models using Ordinary Least Squares (OLS) regression.\n",
    "   - You have worked with formulas involving main effects and interactions, incorporating multiple features (such as `$Attack$`, `$Defense$`, and `$Speed$`) and their interactions.\n",
    "   - You've used model fitting techniques, evaluated in-sample and out-of-sample performance by calculating $R^2$ values.\n",
    "\n",
    "2. **Model Evaluation**:\n",
    "   - You learned how to calculate the **in-sample $R^2$** to assess how well the model fits the training data, and the **out-of-sample $R^2$** to evaluate the model's generalizability on the test data.\n",
    "   - These evaluations provide insight into the model's predictive power both on the data it was trained on and on new, unseen data.\n",
    "\n",
    "3. **Code Walkthroughs**:\n",
    "   - We went through multiple code snippets, breaking down the purpose of each line and explaining how to interpret the results (such as using `.fit()`, `.summary()`, `.predict()`, and calculating correlation coefficients for $R^2$).\n",
    "   - I clarified how to handle large interaction terms and warned about potential computational challenges when including too many categorical variables with many unique values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b3794c",
   "metadata": {},
   "source": [
    "[Chatbot transcript](https://chatgpt.com/share/6732520e-8210-800f-8e09-a5a3da28c048)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aedcf0",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "In a regression model, the design matrix (`model4_spec.exog`) contains the predictor variables (`independent variables`) that are used to predict the outcome variable (`model4_spec.endog`). The linear form specification (`model4_linear_form`) defines how these predictor variables are constructed and included in the design matrix.\n",
    "The design matrix then contains columns for:\n",
    "\n",
    "- Main effects: Transformed predictors (e.g., `scale(center(Attack))`, `scale(center(Defense))`).\n",
    "- Interaction terms: Products of predictors (e.g., `scale(center(Attack)) * scale(center(Defense))`).\n",
    "These columns represent the predictors used to predict the outcome variable (`model4_spec.endog`). The model fits coefficients to these columns, and the prediction is a weighted sum of them.\n",
    "\n",
    "Multicollinearity occurs when predictor variables in the design matrix (`model4_spec.exog`) are highly correlated. This leads to redundant information, making it difficult for the model to determine the individual contribution of each predictor. The result is unstable coefficient estimates with inflated standard errors, which hampers model interpretability and reliability.\n",
    "\n",
    "This instability causes overfitting, where the model learns not only the true relationships but also noise specific to the training data, leading to poor out-of-sample generalization. High condition numbers (e.g., 12 trillion) indicate severe multicollinearity, exacerbating the model’s sensitivity to small data changes and making it perform poorly on new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b245195c",
   "metadata": {},
   "source": [
    "### Summary of Interactions with ChatGPT\n",
    "- Interactions in a regression model occur when the effect of one predictor on the outcome variable depends on the level of another predictor. In the formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8639253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "HP ~ scale(center(Attack)) * scale(center(Defense)) * scale(center(Speed)) * Legendary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d42e929",
   "metadata": {},
   "source": [
    "The `*` operator creates interaction terms between predictors. For example:\n",
    "\n",
    "- `scale(center(Attack)) * scale(center(Defense))` captures the combined effect of `Attack` and `Defense` on `HP`.\n",
    "- Adding more predictors (like `Speed` and `Legendary`) creates higher-order interactions, like `Attack * Defense * Speed` and `Attack * Defense * Speed * Legendary`, which allow the model to account for how multiple predictors jointly affect the outcome.\n",
    "\n",
    "These interactions increase the complexity of the design matrix, creating new columns for each interaction term, leading to a more detailed (and potentially more overfitted) model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82431afc",
   "metadata": {},
   "source": [
    "[Chatbot transcript](https://chatgpt.com/share/673255f6-c268-800f-97d6-91ddfed1eb3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537c5b38",
   "metadata": {},
   "source": [
    "## Question 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d802a58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 11 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>9.48e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:17:06</td>     <th>  Log-Likelihood:    </th> <td> -1765.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3624.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   353</td>      <th>  BIC:               </th> <td>   3812.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    46</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                  <td>   10.1046</td> <td>   14.957</td> <td>    0.676</td> <td> 0.500</td> <td>  -19.312</td> <td>   39.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]</th>          <td>   -3.2717</td> <td>    4.943</td> <td>   -0.662</td> <td> 0.508</td> <td>  -12.992</td> <td>    6.449</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.2]</th>         <td>    9.2938</td> <td>    4.015</td> <td>    2.315</td> <td> 0.021</td> <td>    1.398</td> <td>   17.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.3]</th>         <td>    2.3150</td> <td>    3.915</td> <td>    0.591</td> <td> 0.555</td> <td>   -5.385</td> <td>   10.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.4]</th>         <td>    4.8353</td> <td>    4.149</td> <td>    1.165</td> <td> 0.245</td> <td>   -3.325</td> <td>   12.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.5]</th>         <td>   11.4838</td> <td>    3.960</td> <td>    2.900</td> <td> 0.004</td> <td>    3.696</td> <td>   19.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.6]</th>         <td>    4.9206</td> <td>    4.746</td> <td>    1.037</td> <td> 0.300</td> <td>   -4.413</td> <td>   14.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Dark]</th>     <td>   -1.4155</td> <td>    6.936</td> <td>   -0.204</td> <td> 0.838</td> <td>  -15.057</td> <td>   12.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Dragon]</th>   <td>    0.8509</td> <td>    6.900</td> <td>    0.123</td> <td> 0.902</td> <td>  -12.720</td> <td>   14.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Electric]</th> <td>   -6.3641</td> <td>    6.537</td> <td>   -0.974</td> <td> 0.331</td> <td>  -19.220</td> <td>    6.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fairy]</th>    <td>   -1.9486</td> <td>   10.124</td> <td>   -0.192</td> <td> 0.847</td> <td>  -21.859</td> <td>   17.962</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fighting]</th> <td>    7.0308</td> <td>    7.432</td> <td>    0.946</td> <td> 0.345</td> <td>   -7.586</td> <td>   21.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fire]</th>     <td>    3.0779</td> <td>    6.677</td> <td>    0.461</td> <td> 0.645</td> <td>  -10.055</td> <td>   16.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Flying]</th>   <td>   -2.1231</td> <td>   22.322</td> <td>   -0.095</td> <td> 0.924</td> <td>  -46.025</td> <td>   41.779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ghost]</th>    <td>    5.7343</td> <td>    8.488</td> <td>    0.676</td> <td> 0.500</td> <td>  -10.960</td> <td>   22.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Grass]</th>    <td>    3.3275</td> <td>    5.496</td> <td>    0.605</td> <td> 0.545</td> <td>   -7.481</td> <td>   14.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ground]</th>   <td>    9.5118</td> <td>    7.076</td> <td>    1.344</td> <td> 0.180</td> <td>   -4.404</td> <td>   23.428</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ice]</th>      <td>   -0.9313</td> <td>    7.717</td> <td>   -0.121</td> <td> 0.904</td> <td>  -16.108</td> <td>   14.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Normal]</th>   <td>   18.4816</td> <td>    5.312</td> <td>    3.479</td> <td> 0.001</td> <td>    8.034</td> <td>   28.929</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Poison]</th>   <td>    8.3411</td> <td>    7.735</td> <td>    1.078</td> <td> 0.282</td> <td>   -6.871</td> <td>   23.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Psychic]</th>  <td>    1.8061</td> <td>    6.164</td> <td>    0.293</td> <td> 0.770</td> <td>  -10.317</td> <td>   13.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Rock]</th>     <td>   -3.8558</td> <td>    6.503</td> <td>   -0.593</td> <td> 0.554</td> <td>  -16.645</td> <td>    8.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Steel]</th>    <td>   -4.0053</td> <td>    8.044</td> <td>   -0.498</td> <td> 0.619</td> <td>  -19.826</td> <td>   11.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Water]</th>    <td>    9.7988</td> <td>    5.166</td> <td>    1.897</td> <td> 0.059</td> <td>   -0.361</td> <td>   19.959</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Dark]</th>     <td>    5.8719</td> <td>   15.185</td> <td>    0.387</td> <td> 0.699</td> <td>  -23.993</td> <td>   35.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Dragon]</th>   <td>   13.2777</td> <td>   14.895</td> <td>    0.891</td> <td> 0.373</td> <td>  -16.016</td> <td>   42.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Electric]</th> <td>   14.3228</td> <td>   17.314</td> <td>    0.827</td> <td> 0.409</td> <td>  -19.728</td> <td>   48.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fairy]</th>    <td>    2.8426</td> <td>   14.268</td> <td>    0.199</td> <td> 0.842</td> <td>  -25.218</td> <td>   30.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fighting]</th> <td>    1.9741</td> <td>   14.089</td> <td>    0.140</td> <td> 0.889</td> <td>  -25.735</td> <td>   29.683</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fire]</th>     <td>    0.2001</td> <td>   15.730</td> <td>    0.013</td> <td> 0.990</td> <td>  -30.736</td> <td>   31.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Flying]</th>   <td>    6.7292</td> <td>   13.581</td> <td>    0.495</td> <td> 0.621</td> <td>  -19.980</td> <td>   33.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ghost]</th>    <td>  -10.9402</td> <td>   15.895</td> <td>   -0.688</td> <td> 0.492</td> <td>  -42.201</td> <td>   20.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Grass]</th>    <td>    2.5119</td> <td>   14.540</td> <td>    0.173</td> <td> 0.863</td> <td>  -26.084</td> <td>   31.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ground]</th>   <td>   13.6042</td> <td>   13.655</td> <td>    0.996</td> <td> 0.320</td> <td>  -13.250</td> <td>   40.459</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ice]</th>      <td>   19.7950</td> <td>   15.068</td> <td>    1.314</td> <td> 0.190</td> <td>   -9.840</td> <td>   49.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.None]</th>     <td>    7.6068</td> <td>   13.162</td> <td>    0.578</td> <td> 0.564</td> <td>  -18.279</td> <td>   33.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Normal]</th>   <td>   17.3191</td> <td>   17.764</td> <td>    0.975</td> <td> 0.330</td> <td>  -17.618</td> <td>   52.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Poison]</th>   <td>    0.7770</td> <td>   14.575</td> <td>    0.053</td> <td> 0.958</td> <td>  -27.887</td> <td>   29.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Psychic]</th>  <td>    4.2480</td> <td>   14.174</td> <td>    0.300</td> <td> 0.765</td> <td>  -23.628</td> <td>   32.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Rock]</th>     <td>    6.8858</td> <td>   16.221</td> <td>    0.424</td> <td> 0.671</td> <td>  -25.017</td> <td>   38.788</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Steel]</th>    <td>  -11.9623</td> <td>   14.973</td> <td>   -0.799</td> <td> 0.425</td> <td>  -41.409</td> <td>   17.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Water]</th>    <td>    5.8097</td> <td>   14.763</td> <td>    0.394</td> <td> 0.694</td> <td>  -23.225</td> <td>   34.845</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                     <td>    0.2508</td> <td>    0.051</td> <td>    4.940</td> <td> 0.000</td> <td>    0.151</td> <td>    0.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>                    <td>   -0.0096</td> <td>    0.060</td> <td>   -0.160</td> <td> 0.873</td> <td>   -0.127</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                      <td>   -0.1538</td> <td>    0.051</td> <td>   -2.998</td> <td> 0.003</td> <td>   -0.255</td> <td>   -0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>               <td>    0.3484</td> <td>    0.059</td> <td>    5.936</td> <td> 0.000</td> <td>    0.233</td> <td>    0.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>               <td>    0.1298</td> <td>    0.051</td> <td>    2.525</td> <td> 0.012</td> <td>    0.029</td> <td>    0.231</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>286.476</td> <th>  Durbin-Watson:     </th> <td>   1.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5187.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.807</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>19.725</td>  <th>  Cond. No.          </th> <td>9.21e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 9.21e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}             &        HP        & \\textbf{  R-squared:         } &     0.392   \\\\\n",
       "\\textbf{Model:}                     &       OLS        & \\textbf{  Adj. R-squared:    } &     0.313   \\\\\n",
       "\\textbf{Method:}                    &  Least Squares   & \\textbf{  F-statistic:       } &     4.948   \\\\\n",
       "\\textbf{Date:}                      & Mon, 11 Nov 2024 & \\textbf{  Prob (F-statistic):} &  9.48e-19   \\\\\n",
       "\\textbf{Time:}                      &     19:17:06     & \\textbf{  Log-Likelihood:    } &   -1765.0   \\\\\n",
       "\\textbf{No. Observations:}          &         400      & \\textbf{  AIC:               } &     3624.   \\\\\n",
       "\\textbf{Df Residuals:}              &         353      & \\textbf{  BIC:               } &     3812.   \\\\\n",
       "\\textbf{Df Model:}                  &          46      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}           &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                    & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                  &      10.1046  &       14.957     &     0.676  &         0.500        &      -19.312    &       39.521     \\\\\n",
       "\\textbf{Legendary[T.True]}          &      -3.2717  &        4.943     &    -0.662  &         0.508        &      -12.992    &        6.449     \\\\\n",
       "\\textbf{C(Generation)[T.2]}         &       9.2938  &        4.015     &     2.315  &         0.021        &        1.398    &       17.189     \\\\\n",
       "\\textbf{C(Generation)[T.3]}         &       2.3150  &        3.915     &     0.591  &         0.555        &       -5.385    &       10.015     \\\\\n",
       "\\textbf{C(Generation)[T.4]}         &       4.8353  &        4.149     &     1.165  &         0.245        &       -3.325    &       12.995     \\\\\n",
       "\\textbf{C(Generation)[T.5]}         &      11.4838  &        3.960     &     2.900  &         0.004        &        3.696    &       19.272     \\\\\n",
       "\\textbf{C(Generation)[T.6]}         &       4.9206  &        4.746     &     1.037  &         0.300        &       -4.413    &       14.254     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Dark]}     &      -1.4155  &        6.936     &    -0.204  &         0.838        &      -15.057    &       12.226     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Dragon]}   &       0.8509  &        6.900     &     0.123  &         0.902        &      -12.720    &       14.422     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Electric]} &      -6.3641  &        6.537     &    -0.974  &         0.331        &      -19.220    &        6.491     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fairy]}    &      -1.9486  &       10.124     &    -0.192  &         0.847        &      -21.859    &       17.962     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fighting]} &       7.0308  &        7.432     &     0.946  &         0.345        &       -7.586    &       21.648     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fire]}     &       3.0779  &        6.677     &     0.461  &         0.645        &      -10.055    &       16.210     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Flying]}   &      -2.1231  &       22.322     &    -0.095  &         0.924        &      -46.025    &       41.779     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ghost]}    &       5.7343  &        8.488     &     0.676  &         0.500        &      -10.960    &       22.429     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Grass]}    &       3.3275  &        5.496     &     0.605  &         0.545        &       -7.481    &       14.136     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ground]}   &       9.5118  &        7.076     &     1.344  &         0.180        &       -4.404    &       23.428     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ice]}      &      -0.9313  &        7.717     &    -0.121  &         0.904        &      -16.108    &       14.246     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Normal]}   &      18.4816  &        5.312     &     3.479  &         0.001        &        8.034    &       28.929     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Poison]}   &       8.3411  &        7.735     &     1.078  &         0.282        &       -6.871    &       23.554     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Psychic]}  &       1.8061  &        6.164     &     0.293  &         0.770        &      -10.317    &       13.930     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Rock]}     &      -3.8558  &        6.503     &    -0.593  &         0.554        &      -16.645    &        8.933     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Steel]}    &      -4.0053  &        8.044     &    -0.498  &         0.619        &      -19.826    &       11.816     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Water]}    &       9.7988  &        5.166     &     1.897  &         0.059        &       -0.361    &       19.959     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Dark]}     &       5.8719  &       15.185     &     0.387  &         0.699        &      -23.993    &       35.737     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Dragon]}   &      13.2777  &       14.895     &     0.891  &         0.373        &      -16.016    &       42.571     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Electric]} &      14.3228  &       17.314     &     0.827  &         0.409        &      -19.728    &       48.374     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fairy]}    &       2.8426  &       14.268     &     0.199  &         0.842        &      -25.218    &       30.903     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fighting]} &       1.9741  &       14.089     &     0.140  &         0.889        &      -25.735    &       29.683     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fire]}     &       0.2001  &       15.730     &     0.013  &         0.990        &      -30.736    &       31.136     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Flying]}   &       6.7292  &       13.581     &     0.495  &         0.621        &      -19.980    &       33.438     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ghost]}    &     -10.9402  &       15.895     &    -0.688  &         0.492        &      -42.201    &       20.321     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Grass]}    &       2.5119  &       14.540     &     0.173  &         0.863        &      -26.084    &       31.108     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ground]}   &      13.6042  &       13.655     &     0.996  &         0.320        &      -13.250    &       40.459     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ice]}      &      19.7950  &       15.068     &     1.314  &         0.190        &       -9.840    &       49.430     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.None]}     &       7.6068  &       13.162     &     0.578  &         0.564        &      -18.279    &       33.493     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Normal]}   &      17.3191  &       17.764     &     0.975  &         0.330        &      -17.618    &       52.256     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Poison]}   &       0.7770  &       14.575     &     0.053  &         0.958        &      -27.887    &       29.441     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Psychic]}  &       4.2480  &       14.174     &     0.300  &         0.765        &      -23.628    &       32.124     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Rock]}     &       6.8858  &       16.221     &     0.424  &         0.671        &      -25.017    &       38.788     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Steel]}    &     -11.9623  &       14.973     &    -0.799  &         0.425        &      -41.409    &       17.485     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Water]}    &       5.8097  &       14.763     &     0.394  &         0.694        &      -23.225    &       34.845     \\\\\n",
       "\\textbf{Attack}                     &       0.2508  &        0.051     &     4.940  &         0.000        &        0.151    &        0.351     \\\\\n",
       "\\textbf{Defense}                    &      -0.0096  &        0.060     &    -0.160  &         0.873        &       -0.127    &        0.108     \\\\\n",
       "\\textbf{Speed}                      &      -0.1538  &        0.051     &    -2.998  &         0.003        &       -0.255    &       -0.053     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}               &       0.3484  &        0.059     &     5.936  &         0.000        &        0.233    &        0.464     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}               &       0.1298  &        0.051     &     2.525  &         0.012        &        0.029    &        0.231     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 286.476 & \\textbf{  Durbin-Watson:     } &    1.917  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5187.327  \\\\\n",
       "\\textbf{Skew:}          &   2.807 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  19.725 & \\textbf{  Cond. No.          } & 9.21e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 9.21e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.392\n",
       "Model:                            OLS   Adj. R-squared:                  0.313\n",
       "Method:                 Least Squares   F-statistic:                     4.948\n",
       "Date:                Mon, 11 Nov 2024   Prob (F-statistic):           9.48e-19\n",
       "Time:                        19:17:06   Log-Likelihood:                -1765.0\n",
       "No. Observations:                 400   AIC:                             3624.\n",
       "Df Residuals:                     353   BIC:                             3812.\n",
       "Df Model:                          46                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================================\n",
       "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "Intercept                     10.1046     14.957      0.676      0.500     -19.312      39.521\n",
       "Legendary[T.True]             -3.2717      4.943     -0.662      0.508     -12.992       6.449\n",
       "C(Generation)[T.2]             9.2938      4.015      2.315      0.021       1.398      17.189\n",
       "C(Generation)[T.3]             2.3150      3.915      0.591      0.555      -5.385      10.015\n",
       "C(Generation)[T.4]             4.8353      4.149      1.165      0.245      -3.325      12.995\n",
       "C(Generation)[T.5]            11.4838      3.960      2.900      0.004       3.696      19.272\n",
       "C(Generation)[T.6]             4.9206      4.746      1.037      0.300      -4.413      14.254\n",
       "C(Q(\"Type 1\"))[T.Dark]        -1.4155      6.936     -0.204      0.838     -15.057      12.226\n",
       "C(Q(\"Type 1\"))[T.Dragon]       0.8509      6.900      0.123      0.902     -12.720      14.422\n",
       "C(Q(\"Type 1\"))[T.Electric]    -6.3641      6.537     -0.974      0.331     -19.220       6.491\n",
       "C(Q(\"Type 1\"))[T.Fairy]       -1.9486     10.124     -0.192      0.847     -21.859      17.962\n",
       "C(Q(\"Type 1\"))[T.Fighting]     7.0308      7.432      0.946      0.345      -7.586      21.648\n",
       "C(Q(\"Type 1\"))[T.Fire]         3.0779      6.677      0.461      0.645     -10.055      16.210\n",
       "C(Q(\"Type 1\"))[T.Flying]      -2.1231     22.322     -0.095      0.924     -46.025      41.779\n",
       "C(Q(\"Type 1\"))[T.Ghost]        5.7343      8.488      0.676      0.500     -10.960      22.429\n",
       "C(Q(\"Type 1\"))[T.Grass]        3.3275      5.496      0.605      0.545      -7.481      14.136\n",
       "C(Q(\"Type 1\"))[T.Ground]       9.5118      7.076      1.344      0.180      -4.404      23.428\n",
       "C(Q(\"Type 1\"))[T.Ice]         -0.9313      7.717     -0.121      0.904     -16.108      14.246\n",
       "C(Q(\"Type 1\"))[T.Normal]      18.4816      5.312      3.479      0.001       8.034      28.929\n",
       "C(Q(\"Type 1\"))[T.Poison]       8.3411      7.735      1.078      0.282      -6.871      23.554\n",
       "C(Q(\"Type 1\"))[T.Psychic]      1.8061      6.164      0.293      0.770     -10.317      13.930\n",
       "C(Q(\"Type 1\"))[T.Rock]        -3.8558      6.503     -0.593      0.554     -16.645       8.933\n",
       "C(Q(\"Type 1\"))[T.Steel]       -4.0053      8.044     -0.498      0.619     -19.826      11.816\n",
       "C(Q(\"Type 1\"))[T.Water]        9.7988      5.166      1.897      0.059      -0.361      19.959\n",
       "C(Q(\"Type 2\"))[T.Dark]         5.8719     15.185      0.387      0.699     -23.993      35.737\n",
       "C(Q(\"Type 2\"))[T.Dragon]      13.2777     14.895      0.891      0.373     -16.016      42.571\n",
       "C(Q(\"Type 2\"))[T.Electric]    14.3228     17.314      0.827      0.409     -19.728      48.374\n",
       "C(Q(\"Type 2\"))[T.Fairy]        2.8426     14.268      0.199      0.842     -25.218      30.903\n",
       "C(Q(\"Type 2\"))[T.Fighting]     1.9741     14.089      0.140      0.889     -25.735      29.683\n",
       "C(Q(\"Type 2\"))[T.Fire]         0.2001     15.730      0.013      0.990     -30.736      31.136\n",
       "C(Q(\"Type 2\"))[T.Flying]       6.7292     13.581      0.495      0.621     -19.980      33.438\n",
       "C(Q(\"Type 2\"))[T.Ghost]      -10.9402     15.895     -0.688      0.492     -42.201      20.321\n",
       "C(Q(\"Type 2\"))[T.Grass]        2.5119     14.540      0.173      0.863     -26.084      31.108\n",
       "C(Q(\"Type 2\"))[T.Ground]      13.6042     13.655      0.996      0.320     -13.250      40.459\n",
       "C(Q(\"Type 2\"))[T.Ice]         19.7950     15.068      1.314      0.190      -9.840      49.430\n",
       "C(Q(\"Type 2\"))[T.None]         7.6068     13.162      0.578      0.564     -18.279      33.493\n",
       "C(Q(\"Type 2\"))[T.Normal]      17.3191     17.764      0.975      0.330     -17.618      52.256\n",
       "C(Q(\"Type 2\"))[T.Poison]       0.7770     14.575      0.053      0.958     -27.887      29.441\n",
       "C(Q(\"Type 2\"))[T.Psychic]      4.2480     14.174      0.300      0.765     -23.628      32.124\n",
       "C(Q(\"Type 2\"))[T.Rock]         6.8858     16.221      0.424      0.671     -25.017      38.788\n",
       "C(Q(\"Type 2\"))[T.Steel]      -11.9623     14.973     -0.799      0.425     -41.409      17.485\n",
       "C(Q(\"Type 2\"))[T.Water]        5.8097     14.763      0.394      0.694     -23.225      34.845\n",
       "Attack                         0.2508      0.051      4.940      0.000       0.151       0.351\n",
       "Defense                       -0.0096      0.060     -0.160      0.873      -0.127       0.108\n",
       "Speed                         -0.1538      0.051     -2.998      0.003      -0.255      -0.053\n",
       "Q(\"Sp. Def\")                   0.3484      0.059      5.936      0.000       0.233       0.464\n",
       "Q(\"Sp. Atk\")                   0.1298      0.051      2.525      0.012       0.029       0.231\n",
       "==============================================================================\n",
       "Omnibus:                      286.476   Durbin-Watson:                   1.917\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5187.327\n",
       "Skew:                           2.807   Prob(JB):                         0.00\n",
       "Kurtosis:                      19.725   Cond. No.                     9.21e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 9.21e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the linear formula for model5, adding continuous and categorical predictors\n",
    "model5_linear_form = 'HP ~ Attack + Defense + Speed + Legendary'\n",
    "model5_linear_form += ' + Q(\"Sp. Def\") + Q(\"Sp. Atk\")'\n",
    "model5_linear_form += ' + C(Generation) + C(Q(\"Type 1\")) + C(Q(\"Type 2\"))'\n",
    "\n",
    "# Define the model using OLS (Ordinary Least Squares) regression with the formula\n",
    "model5_spec = smf.ols(formula=model5_linear_form, data=pokeaman_train)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model5_fit = model5_spec.fit()\n",
    "\n",
    "# Display the summary of model5 (coefficients, R-squared, etc.)\n",
    "model5_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e783fe6",
   "metadata": {},
   "source": [
    "- `model5_linear_form` is an extension of `model4_fit` by including more features, such as special defensive and attack stats, along with categorical variables for Pokémon's generation and types, broadening the model to capture more complex relationships in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "317a514e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3920134083531893\n",
      "'Out of sample' R-squared: 0.30015614488652215\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for the test set using model5\n",
    "yhat_model5 = model5_fit.predict(pokeaman_test)\n",
    "\n",
    "# Extract the true HP values from the test set for comparison\n",
    "y = pokeaman_test.HP\n",
    "\n",
    "# Print the in-sample R-squared value from model5 (goodness of fit on training data)\n",
    "print(\"'In sample' R-squared:    \", model5_fit.rsquared)\n",
    "\n",
    "# Compute and print the out-of-sample R-squared:\n",
    "# 1. Calculate the correlation between true values (y) and predicted values (yhat_model5)\n",
    "# 2. Square the correlation coefficient to get the out-of-sample R-squared\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y, yhat_model5)[0,1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333ed850",
   "metadata": {},
   "source": [
    "- The in-sample R-squared reflects how well the model fits the training data, while the out-of-sample R-squared shows how well the model performs when applied to new test data, providing a measure of the model's generalizability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bfd9f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   24.36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 11 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>2.25e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:17:53</td>     <th>  Log-Likelihood:    </th> <td> -1783.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3585.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   391</td>      <th>  BIC:               </th> <td>   3621.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                   <td></td>                     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                          <td>   22.8587</td> <td>    3.876</td> <td>    5.897</td> <td> 0.000</td> <td>   15.238</td> <td>   30.479</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Normal\")[T.True]</th> <td>   17.5594</td> <td>    3.339</td> <td>    5.258</td> <td> 0.000</td> <td>   10.994</td> <td>   24.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Water\")[T.True]</th>  <td>    9.0301</td> <td>    3.172</td> <td>    2.847</td> <td> 0.005</td> <td>    2.794</td> <td>   15.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 2)[T.True]</th>         <td>    6.5293</td> <td>    2.949</td> <td>    2.214</td> <td> 0.027</td> <td>    0.732</td> <td>   12.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 5)[T.True]</th>         <td>    8.4406</td> <td>    2.711</td> <td>    3.114</td> <td> 0.002</td> <td>    3.112</td> <td>   13.770</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                             <td>    0.2454</td> <td>    0.037</td> <td>    6.639</td> <td> 0.000</td> <td>    0.173</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                              <td>   -0.1370</td> <td>    0.045</td> <td>   -3.028</td> <td> 0.003</td> <td>   -0.226</td> <td>   -0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                       <td>    0.3002</td> <td>    0.045</td> <td>    6.662</td> <td> 0.000</td> <td>    0.212</td> <td>    0.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                       <td>    0.1192</td> <td>    0.042</td> <td>    2.828</td> <td> 0.005</td> <td>    0.036</td> <td>    0.202</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>271.290</td> <th>  Durbin-Watson:     </th> <td>   1.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4238.692</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.651</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>18.040</td>  <th>  Cond. No.          </th> <td>    618.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                     &        HP        & \\textbf{  R-squared:         } &     0.333   \\\\\n",
       "\\textbf{Model:}                             &       OLS        & \\textbf{  Adj. R-squared:    } &     0.319   \\\\\n",
       "\\textbf{Method:}                            &  Least Squares   & \\textbf{  F-statistic:       } &     24.36   \\\\\n",
       "\\textbf{Date:}                              & Mon, 11 Nov 2024 & \\textbf{  Prob (F-statistic):} &  2.25e-30   \\\\\n",
       "\\textbf{Time:}                              &     19:17:53     & \\textbf{  Log-Likelihood:    } &   -1783.6   \\\\\n",
       "\\textbf{No. Observations:}                  &         400      & \\textbf{  AIC:               } &     3585.   \\\\\n",
       "\\textbf{Df Residuals:}                      &         391      & \\textbf{  BIC:               } &     3621.   \\\\\n",
       "\\textbf{Df Model:}                          &           8      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                   &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                            & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                          &      22.8587  &        3.876     &     5.897  &         0.000        &       15.238    &       30.479     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Normal\")[T.True]} &      17.5594  &        3.339     &     5.258  &         0.000        &       10.994    &       24.125     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Water\")[T.True]}  &       9.0301  &        3.172     &     2.847  &         0.005        &        2.794    &       15.266     \\\\\n",
       "\\textbf{I(Generation == 2)[T.True]}         &       6.5293  &        2.949     &     2.214  &         0.027        &        0.732    &       12.327     \\\\\n",
       "\\textbf{I(Generation == 5)[T.True]}         &       8.4406  &        2.711     &     3.114  &         0.002        &        3.112    &       13.770     \\\\\n",
       "\\textbf{Attack}                             &       0.2454  &        0.037     &     6.639  &         0.000        &        0.173    &        0.318     \\\\\n",
       "\\textbf{Speed}                              &      -0.1370  &        0.045     &    -3.028  &         0.003        &       -0.226    &       -0.048     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                       &       0.3002  &        0.045     &     6.662  &         0.000        &        0.212    &        0.389     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                       &       0.1192  &        0.042     &     2.828  &         0.005        &        0.036    &        0.202     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 271.290 & \\textbf{  Durbin-Watson:     } &    1.999  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 4238.692  \\\\\n",
       "\\textbf{Skew:}          &   2.651 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  18.040 & \\textbf{  Cond. No.          } &     618.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.333\n",
       "Model:                            OLS   Adj. R-squared:                  0.319\n",
       "Method:                 Least Squares   F-statistic:                     24.36\n",
       "Date:                Mon, 11 Nov 2024   Prob (F-statistic):           2.25e-30\n",
       "Time:                        19:17:53   Log-Likelihood:                -1783.6\n",
       "No. Observations:                 400   AIC:                             3585.\n",
       "Df Residuals:                     391   BIC:                             3621.\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================================\n",
       "                                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------\n",
       "Intercept                             22.8587      3.876      5.897      0.000      15.238      30.479\n",
       "I(Q(\"Type 1\") == \"Normal\")[T.True]    17.5594      3.339      5.258      0.000      10.994      24.125\n",
       "I(Q(\"Type 1\") == \"Water\")[T.True]      9.0301      3.172      2.847      0.005       2.794      15.266\n",
       "I(Generation == 2)[T.True]             6.5293      2.949      2.214      0.027       0.732      12.327\n",
       "I(Generation == 5)[T.True]             8.4406      2.711      3.114      0.002       3.112      13.770\n",
       "Attack                                 0.2454      0.037      6.639      0.000       0.173       0.318\n",
       "Speed                                 -0.1370      0.045     -3.028      0.003      -0.226      -0.048\n",
       "Q(\"Sp. Def\")                           0.3002      0.045      6.662      0.000       0.212       0.389\n",
       "Q(\"Sp. Atk\")                           0.1192      0.042      2.828      0.005       0.036       0.202\n",
       "==============================================================================\n",
       "Omnibus:                      271.290   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4238.692\n",
       "Skew:                           2.651   Prob(JB):                         0.00\n",
       "Kurtosis:                      18.040   Cond. No.                         618.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the linear formula for model6, simplifying the predictor set from model5\n",
    "model6_linear_form = 'HP ~ Attack + Speed + Q(\"Sp. Def\") + Q(\"Sp. Atk\")'\n",
    "\n",
    "# Add significant indicator variables based on the previous model (model5)\n",
    "model6_linear_form += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model6_linear_form += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model6_linear_form += ' + I(Generation==2)'\n",
    "model6_linear_form += ' + I(Generation==5)'\n",
    "\n",
    "# Define the model using OLS regression with the new formula\n",
    "model6_spec = smf.ols(formula=model6_linear_form, data=pokeaman_train)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model6_fit = model6_spec.fit()\n",
    "\n",
    "# Display the summary of model6 (coefficients, R-squared, etc.)\n",
    "model6_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f1fddb",
   "metadata": {},
   "source": [
    "- `model6_linear_form` is a refined version of `model5_linear_form`, simplifying the predictor set by focusing on significant indicator variables for Pokémon type and generation, aiming to enhance model interpretability while retaining important categorical features.\n",
    "    - Simplifying the model: By reducing the number of continuous predictors (i.e., removing Attack and Speed), the focus shifts to significant categorical features (types and generations). This could be a way to highlight the importance of specific Pokémon types and generations while reducing model complexity.\n",
    "\n",
    "    - Model refinement: The indicator variables added in model6_linear_form are likely derived from previous analysis (significance testing), implying that the focus is on improving predictive accuracy by incorporating only the most relevant categorical variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1602952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3326310334310908\n",
      "'Out of sample' R-squared: 0.29572460427079933\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for the test set using model6\n",
    "yhat_model6 = model6_fit.predict(pokeaman_test)\n",
    "\n",
    "# Extract the true HP values from the test set for comparison\n",
    "y = pokeaman_test.HP\n",
    "\n",
    "# Print the in-sample R-squared value from model6 (goodness of fit on training data)\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared)\n",
    "\n",
    "# Compute and print the out-of-sample R-squared:\n",
    "# 1. Calculate the correlation between true values (y) and predicted values (yhat_model6)\n",
    "# 2. Square the correlation coefficient to get the out-of-sample R-squared\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y, yhat_model6)[0,1]**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9059033a",
   "metadata": {},
   "source": [
    "- The code calculates both in-sample and out-of-sample R-squared values, providing a measure of the model’s fit on the training data and its ability to generalize to the test data.\n",
    "    - The in-sample R-squared will tell you how well model6 fits the training data.\n",
    "    - The out-of-sample R-squared provides an estimate of how well the model generalizes to new, unseen data in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c878a15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   12.16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 11 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>4.20e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:19:43</td>     <th>  Log-Likelihood:    </th> <td> -1769.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3579.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   380</td>      <th>  BIC:               </th> <td>   3659.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    19</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                     <td></td>                       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                              <td>   95.1698</td> <td>   34.781</td> <td>    2.736</td> <td> 0.007</td> <td>   26.783</td> <td>  163.556</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Normal\")[T.True]</th>     <td>   18.3653</td> <td>    3.373</td> <td>    5.445</td> <td> 0.000</td> <td>   11.733</td> <td>   24.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Water\")[T.True]</th>      <td>    9.2913</td> <td>    3.140</td> <td>    2.959</td> <td> 0.003</td> <td>    3.117</td> <td>   15.466</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 2)[T.True]</th>             <td>    7.0711</td> <td>    2.950</td> <td>    2.397</td> <td> 0.017</td> <td>    1.271</td> <td>   12.871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 5)[T.True]</th>             <td>    7.8557</td> <td>    2.687</td> <td>    2.923</td> <td> 0.004</td> <td>    2.572</td> <td>   13.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                                 <td>   -0.6975</td> <td>    0.458</td> <td>   -1.523</td> <td> 0.129</td> <td>   -1.598</td> <td>    0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                                  <td>   -1.8147</td> <td>    0.554</td> <td>   -3.274</td> <td> 0.001</td> <td>   -2.905</td> <td>   -0.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed</th>                           <td>    0.0189</td> <td>    0.007</td> <td>    2.882</td> <td> 0.004</td> <td>    0.006</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                           <td>   -0.5532</td> <td>    0.546</td> <td>   -1.013</td> <td> 0.312</td> <td>   -1.627</td> <td>    0.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\")</th>                    <td>    0.0090</td> <td>    0.007</td> <td>    1.311</td> <td> 0.191</td> <td>   -0.004</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\")</th>                     <td>    0.0208</td> <td>    0.008</td> <td>    2.571</td> <td> 0.011</td> <td>    0.005</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\")</th>              <td>   -0.0002</td> <td> 9.06e-05</td> <td>   -2.277</td> <td> 0.023</td> <td>   -0.000</td> <td>-2.82e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                           <td>   -0.7277</td> <td>    0.506</td> <td>   -1.439</td> <td> 0.151</td> <td>   -1.722</td> <td>    0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Atk\")</th>                    <td>    0.0136</td> <td>    0.005</td> <td>    2.682</td> <td> 0.008</td> <td>    0.004</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Atk\")</th>                     <td>    0.0146</td> <td>    0.007</td> <td>    2.139</td> <td> 0.033</td> <td>    0.001</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Atk\")</th>              <td>   -0.0002</td> <td>  5.4e-05</td> <td>   -3.383</td> <td> 0.001</td> <td>   -0.000</td> <td>-7.65e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>              <td>    0.0103</td> <td>    0.007</td> <td>    1.516</td> <td> 0.130</td> <td>   -0.003</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>       <td>   -0.0001</td> <td> 6.71e-05</td> <td>   -2.119</td> <td> 0.035</td> <td>   -0.000</td> <td>-1.03e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>        <td>   -0.0002</td> <td> 8.82e-05</td> <td>   -2.075</td> <td> 0.039</td> <td>   -0.000</td> <td>-9.62e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th> <td>  2.03e-06</td> <td> 7.42e-07</td> <td>    2.734</td> <td> 0.007</td> <td>  5.7e-07</td> <td> 3.49e-06</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>2.34e+09</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.34e+09. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                         &        HP        & \\textbf{  R-squared:         } &     0.378   \\\\\n",
       "\\textbf{Model:}                                 &       OLS        & \\textbf{  Adj. R-squared:    } &     0.347   \\\\\n",
       "\\textbf{Method:}                                &  Least Squares   & \\textbf{  F-statistic:       } &     12.16   \\\\\n",
       "\\textbf{Date:}                                  & Mon, 11 Nov 2024 & \\textbf{  Prob (F-statistic):} &  4.20e-29   \\\\\n",
       "\\textbf{Time:}                                  &     19:19:43     & \\textbf{  Log-Likelihood:    } &   -1769.5   \\\\\n",
       "\\textbf{No. Observations:}                      &         400      & \\textbf{  AIC:               } &     3579.   \\\\\n",
       "\\textbf{Df Residuals:}                          &         380      & \\textbf{  BIC:               } &     3659.   \\\\\n",
       "\\textbf{Df Model:}                              &          19      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                       &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                              &      95.1698  &       34.781     &     2.736  &         0.007        &       26.783    &      163.556     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Normal\")[T.True]}     &      18.3653  &        3.373     &     5.445  &         0.000        &       11.733    &       24.997     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Water\")[T.True]}      &       9.2913  &        3.140     &     2.959  &         0.003        &        3.117    &       15.466     \\\\\n",
       "\\textbf{I(Generation == 2)[T.True]}             &       7.0711  &        2.950     &     2.397  &         0.017        &        1.271    &       12.871     \\\\\n",
       "\\textbf{I(Generation == 5)[T.True]}             &       7.8557  &        2.687     &     2.923  &         0.004        &        2.572    &       13.140     \\\\\n",
       "\\textbf{Attack}                                 &      -0.6975  &        0.458     &    -1.523  &         0.129        &       -1.598    &        0.203     \\\\\n",
       "\\textbf{Speed}                                  &      -1.8147  &        0.554     &    -3.274  &         0.001        &       -2.905    &       -0.725     \\\\\n",
       "\\textbf{Attack:Speed}                           &       0.0189  &        0.007     &     2.882  &         0.004        &        0.006    &        0.032     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                           &      -0.5532  &        0.546     &    -1.013  &         0.312        &       -1.627    &        0.521     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\")}                    &       0.0090  &        0.007     &     1.311  &         0.191        &       -0.004    &        0.023     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\")}                     &       0.0208  &        0.008     &     2.571  &         0.011        &        0.005    &        0.037     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\")}              &      -0.0002  &     9.06e-05     &    -2.277  &         0.023        &       -0.000    &    -2.82e-05     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                           &      -0.7277  &        0.506     &    -1.439  &         0.151        &       -1.722    &        0.267     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Atk\")}                    &       0.0136  &        0.005     &     2.682  &         0.008        &        0.004    &        0.024     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Atk\")}                     &       0.0146  &        0.007     &     2.139  &         0.033        &        0.001    &        0.028     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Atk\")}              &      -0.0002  &      5.4e-05     &    -3.383  &         0.001        &       -0.000    &    -7.65e-05     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):Q(\"Sp. Atk\")}              &       0.0103  &        0.007     &     1.516  &         0.130        &       -0.003    &        0.024     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}       &      -0.0001  &     6.71e-05     &    -2.119  &         0.035        &       -0.000    &    -1.03e-05     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}        &      -0.0002  &     8.82e-05     &    -2.075  &         0.039        &       -0.000    &    -9.62e-06     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")} &     2.03e-06  &     7.42e-07     &     2.734  &         0.007        &      5.7e-07    &     3.49e-06     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } & 2.34e+09  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.34e+09. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.378\n",
       "Model:                            OLS   Adj. R-squared:                  0.347\n",
       "Method:                 Least Squares   F-statistic:                     12.16\n",
       "Date:                Mon, 11 Nov 2024   Prob (F-statistic):           4.20e-29\n",
       "Time:                        19:19:43   Log-Likelihood:                -1769.5\n",
       "No. Observations:                 400   AIC:                             3579.\n",
       "Df Residuals:                     380   BIC:                             3659.\n",
       "Df Model:                          19                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================================\n",
       "                                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------------------\n",
       "Intercept                                 95.1698     34.781      2.736      0.007      26.783     163.556\n",
       "I(Q(\"Type 1\") == \"Normal\")[T.True]        18.3653      3.373      5.445      0.000      11.733      24.997\n",
       "I(Q(\"Type 1\") == \"Water\")[T.True]          9.2913      3.140      2.959      0.003       3.117      15.466\n",
       "I(Generation == 2)[T.True]                 7.0711      2.950      2.397      0.017       1.271      12.871\n",
       "I(Generation == 5)[T.True]                 7.8557      2.687      2.923      0.004       2.572      13.140\n",
       "Attack                                    -0.6975      0.458     -1.523      0.129      -1.598       0.203\n",
       "Speed                                     -1.8147      0.554     -3.274      0.001      -2.905      -0.725\n",
       "Attack:Speed                               0.0189      0.007      2.882      0.004       0.006       0.032\n",
       "Q(\"Sp. Def\")                              -0.5532      0.546     -1.013      0.312      -1.627       0.521\n",
       "Attack:Q(\"Sp. Def\")                        0.0090      0.007      1.311      0.191      -0.004       0.023\n",
       "Speed:Q(\"Sp. Def\")                         0.0208      0.008      2.571      0.011       0.005       0.037\n",
       "Attack:Speed:Q(\"Sp. Def\")                 -0.0002   9.06e-05     -2.277      0.023      -0.000   -2.82e-05\n",
       "Q(\"Sp. Atk\")                              -0.7277      0.506     -1.439      0.151      -1.722       0.267\n",
       "Attack:Q(\"Sp. Atk\")                        0.0136      0.005      2.682      0.008       0.004       0.024\n",
       "Speed:Q(\"Sp. Atk\")                         0.0146      0.007      2.139      0.033       0.001       0.028\n",
       "Attack:Speed:Q(\"Sp. Atk\")                 -0.0002    5.4e-05     -3.383      0.001      -0.000   -7.65e-05\n",
       "Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  0.0103      0.007      1.516      0.130      -0.003       0.024\n",
       "Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")          -0.0001   6.71e-05     -2.119      0.035      -0.000   -1.03e-05\n",
       "Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           -0.0002   8.82e-05     -2.075      0.039      -0.000   -9.62e-06\n",
       "Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")   2.03e-06   7.42e-07      2.734      0.007     5.7e-07    3.49e-06\n",
       "==============================================================================\n",
       "Omnibus:                      252.300   Durbin-Watson:                   1.953\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3474.611\n",
       "Skew:                           2.438   Prob(JB):                         0.00\n",
       "Kurtosis:                      16.590   Cond. No.                     2.34e+09\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.34e+09. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the linear formula for model7 with interactions between predictors\n",
    "model7_linear_form = 'HP ~ Attack * Speed * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "# This part specifies that the model will include interactions between 'Attack', 'Speed', 'Sp. Def', and 'Sp. Atk'.\n",
    "# The '*' operator indicates the inclusion of both main effects and interactions between the predictors.\n",
    "\n",
    "# Add categorical predictor variables as indicator variables\n",
    "model7_linear_form += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "# This adds an indicator variable for 'Type 1' being \"Normal\". 'I()' creates a binary condition (0 or 1).\n",
    "\n",
    "model7_linear_form += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "# Similarly, this adds an indicator variable for 'Type 1' being \"Water\".\n",
    "\n",
    "model7_linear_form += ' + I(Generation==2)'\n",
    "# This adds an indicator variable for Pokémon from Generation 2. 'I()' creates a binary condition (0 or 1).\n",
    "\n",
    "model7_linear_form += ' + I(Generation==5)'\n",
    "# This adds an indicator variable for Pokémon from Generation 5, again with a binary condition.\n",
    "\n",
    "# Create the OLS model specification with the defined formula and train data\n",
    "model7_spec = smf.ols(formula=model7_linear_form, data=pokeaman_train)\n",
    "# The formula defines the model, and 'pokeaman_train' is the dataset used to train it.\n",
    "\n",
    "# Fit the model to the data\n",
    "model7_fit = model7_spec.fit()\n",
    "# This fits the model using the specified training data.\n",
    "\n",
    "# Display the summary of the fitted model\n",
    "model7_fit.summary()\n",
    "# This displays a summary of the fitted model, including coefficients, R-squared, p-values, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b6eae3",
   "metadata": {},
   "source": [
    "- Model7 extends model6 by incorporating interactions between predictors (e.g., `Attack`, `Speed`, etc.), allowing the model to capture more complex relationships among the variables, which might lead to improved predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dc86924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.37818209127432456\n",
      "'Out of sample' R-squared: 0.35055389205977444\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for the test set using the fitted model7\n",
    "yhat_model7 = model7_fit.predict(pokeaman_test)\n",
    "# This calculates the predicted HP values for each Pokémon in the test set (pokeaman_test) based on model7.\n",
    "\n",
    "# Extract the true HP values from the test set\n",
    "y = pokeaman_test.HP\n",
    "# This stores the actual HP values from the test set for comparison.\n",
    "\n",
    "# Calculate the in-sample R-squared for model7\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared)\n",
    "# This prints the R-squared value for the training data, showing how well the model fits the data it was trained on.\n",
    "\n",
    "# Calculate the out-of-sample R-squared for model7\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y, yhat_model7)[0, 1]**2)\n",
    "# This calculates the correlation coefficient between the true values (y) and the predicted values (yhat_model7),\n",
    "# then squares it to get the out-of-sample R-squared value, which measures how well the model generalizes to the test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc081da1",
   "metadata": {},
   "source": [
    "- The code calculates in-sample R-squared to assess the model’s fit on the training data, and out-of-sample R-squared to evaluate how well the model performs on unseen test data, indicating its ability to generalize.\n",
    "    - In-sample R-squared (`model7_fit.rsquared`): Reflects how well model7 fits the training data.\n",
    "    - Out-of-sample R-squared: Measures how well model7 generalizes to the test data by calculating the correlation between predicted and actual HP values in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5fe8793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>    15.4</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } &     15.4  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the linear formula with centered and scaled continuous predictors\n",
    "model7_linear_form_CS = 'HP ~ scale(center(Attack)) * scale(center(Speed))'\n",
    "# This centers and scales 'Attack' and 'Speed' (subtracting the mean and dividing by the standard deviation),\n",
    "# and includes their interaction in the model.\n",
    "\n",
    "model7_linear_form_CS += ' * scale(center(Q(\"Sp. Def\"))) * scale(center(Q(\"Sp. Atk\")))'\n",
    "# Similarly, 'Sp. Def' and 'Sp. Atk' are centered and scaled, and their interactions with 'Attack' and 'Speed' are included.\n",
    "\n",
    "# Add categorical variables (no scaling or centering applied here)\n",
    "model7_linear_form_CS += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "# Adds an indicator variable for 'Type 1' being \"Normal\".\n",
    "\n",
    "model7_linear_form_CS += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "# Adds an indicator variable for 'Type 1' being \"Water\".\n",
    "\n",
    "model7_linear_form_CS += ' + I(Generation==2)'\n",
    "# Adds an indicator variable for Generation 2 Pokémon.\n",
    "\n",
    "model7_linear_form_CS += ' + I(Generation==5)'\n",
    "# Adds an indicator variable for Generation 5 Pokémon.\n",
    "\n",
    "# Create the OLS model specification with the defined formula and training data\n",
    "model7_CS_spec = smf.ols(formula=model7_linear_form_CS, data=pokeaman_train)\n",
    "# Defines the model and uses the training data ('pokeaman_train') for fitting.\n",
    "\n",
    "# Fit the model\n",
    "model7_CS_fit = model7_CS_spec.fit()\n",
    "# This fits the model using the training data.\n",
    "\n",
    "# Display the model summary (specifically the last table, which includes model statistics)\n",
    "model7_CS_fit.summary().tables[-1] \n",
    "# The 'Cond. No.' (condition number) is now 15.4, which is lower than before due to centering and scaling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddecd8a5",
   "metadata": {},
   "source": [
    "- `model7_linear_form_CS` improves upon `model7_linear_form` by centering and scaling continuous predictors, which improves model stability and helps mitigate issues caused by variables with different scales. The condition number has decreased, suggesting better numerical stability in fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7aa10f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>2.34e+09</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } & 2.34e+09  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Cond. No.\" WAS 2,340,000,000 WITHOUT to centering and scaling\n",
    "model7_fit.summary().tables[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e874f64",
   "metadata": {},
   "source": [
    "Without centering and scaling, the condition number was extremely high (2,340,000,000), indicating potential numerical instability and multicollinearity. After centering and scaling in model7_linear_form_CS, the condition number decreased significantly to 15.4, suggesting improved model stability and reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a164866f",
   "metadata": {},
   "source": [
    "- The development from **model3_fit** to **model7_linear_form** reflects a process of iterative model refinement to better predict **HP**. Starting with **model5_linear_form**, additional predictors such as `Attack`, `Defense`, `Speed`, and categorical variables like `Generation` and Pokémon types were included to expand the model's explanatory power. From **model5_linear_form** to **model6_linear_form**, the model was refined by removing less significant predictors and adding important interaction terms, such as indicator variables for specific Pokémon types and generations, based on statistical significance. Finally, **model7_linear_form** introduces higher-order interaction terms between continuous predictors like `Attack`, `Speed`, and special stats, enabling the model to capture more complex relationships. This progression demonstrates a balance between model complexity and interpretability, moving from broader exploration to a focused, more nuanced understanding of the factors influencing **HP**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e72f9a3",
   "metadata": {},
   "source": [
    "### Summary of Interactions with ChatGPT\n",
    "1. **Model Development Process**:\n",
    "   - We discussed how each model (from **model3_fit** to **model7_linear_form**) was developed and extended. Each model built upon the previous one by adding, refining, or adjusting the predictors and interactions:\n",
    "     - **model5_linear_form**: \n",
    "       - Added more predictors (e.g., `Attack`, `Defense`, `Speed`, etc.).\n",
    "       - Introduced interactions between continuous and categorical variables.\n",
    "     - **model6_linear_form**: \n",
    "       - Simplified by removing some predictors and added significant indicator variables to account for specific types and generations.\n",
    "     - **model7_linear_form**: \n",
    "       - Introduced higher-order interaction terms to capture more complex relationships between continuous predictors.\n",
    "\n",
    "2. **Numerical Stability and Condition Number**:\n",
    "   - We discussed the **condition number** in models before and after centering and scaling:\n",
    "     - **Before centering/scaling**: \n",
    "       - The **condition number** was very high (**2.34e+09**), indicating potential multicollinearity and numerical instability.\n",
    "     - **After centering/scaling**: \n",
    "       - The **condition number** improved to **15.4**, reflecting improved stability and reduced issues with multicollinearity.\n",
    "\n",
    "3. **Model Output Analysis**:\n",
    "   - We analyzed the results of **model7_fit.summary()**, discussing key statistics:\n",
    "     - **Omnibus test** and **Jarque-Bera test** indicated that the residuals deviate significantly from normality.\n",
    "     - **Durbin-Watson statistic** suggested no autocorrelation.\n",
    "     - **Skew** and **Kurtosis** suggested non-normal residuals, with the possibility of outliers or heavy-tailed distributions.\n",
    "   \n",
    "4. **Further Discussion**:\n",
    "   - We explored the rationale for adding interaction terms in the models and why centering and scaling helped improve the model's stability.\n",
    "   - We also touched on ways to address potential issues with residuals and multicollinearity, such as using regularization techniques or different model types.\n",
    "\n",
    "**Overall Summary**:\n",
    "The conversation focused on understanding the evolution of the models, their statistical properties, and ways to improve them for better stability and prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602ec9ec",
   "metadata": {},
   "source": [
    "[Chatbot transcript](https://chatgpt.com/share/67325b05-ac48-800f-aa51-b917a2ec26c3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7da1310",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3b8e4a",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "997e077d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume 'songs' is your dataset\n",
    "# Define the linear model formula\n",
    "linear_form = 'danceability ~ energy * loudness + energy * mode'\n",
    "\n",
    "# Set the number of repetitions for random data splits\n",
    "reps = 100\n",
    "\n",
    "# Arrays to store the R-squared values\n",
    "in_sample_Rsquared = np.array([0.0] * reps)\n",
    "out_of_sample_Rsquared = np.array([0.0] * reps)\n",
    "\n",
    "# Perform 100 iterations of random data splits, model fitting, and R-squared calculations\n",
    "for i in range(reps):\n",
    "    # Split the data into training and testing sets randomly\n",
    "    songs_training_data, songs_testing_data = train_test_split(songs, train_size=31)\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    final_model_fit = smf.ols(formula=linear_form, data=songs_training_data).fit()\n",
    "    \n",
    "    # Store the in-sample R-squared\n",
    "    in_sample_Rsquared[i] = final_model_fit.rsquared\n",
    "    \n",
    "    # Calculate the out-of-sample R-squared (prediction accuracy on the testing data)\n",
    "    out_of_sample_Rsquared[i] = np.corrcoef(songs_testing_data.danceability, \n",
    "                                             final_model_fit.predict(songs_testing_data))[0, 1]**2\n",
    "\n",
    "# Create a DataFrame for easier visualization\n",
    "df = pd.DataFrame({\n",
    "    \"In Sample Performance (R-squared)\": in_sample_Rsquared,\n",
    "    \"Out of Sample Performance (R-squared)\": out_of_sample_Rsquared\n",
    "})\n",
    "\n",
    "# Create a scatter plot to visualize the performance\n",
    "fig = px.scatter(df, x=\"In Sample Performance (R-squared)\", \n",
    "                 y=\"Out of Sample Performance (R-squared)\", \n",
    "                 title=\"In-Sample vs. Out-of-Sample Performance\",\n",
    "                 labels={\"In Sample Performance (R-squared)\": \"In-Sample R²\", \n",
    "                         \"Out of Sample Performance (R-squared)\": \"Out-of-Sample R²\"})\n",
    "\n",
    "# Add a reference line y=x for comparison\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], name=\"y=x\", line=dict(dash='dash', color='red')))\n",
    "\n",
    "# Show the plot\n",
    "fig.show(renderer='png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea274b7b",
   "metadata": {},
   "source": [
    "This code performs 100 random splits of the dataset into training and testing sets. For each split, it fits a regression model, calculates the in-sample R-squared (training data), and out-of-sample R-squared (testing data). The results are visualized in a scatter plot, where each point represents one iteration's in-sample vs. out-of-sample R-squared values. The red line (y=x) shows where the two values would be equal.\n",
    "\n",
    "Purpose:\n",
    "- In-sample vs. out-of-sample R-squared: If the model overfits, the in-sample R-squared will be higher than out-of-sample. If it underfits, the reverse is true.\n",
    "- This helps assess the model’s generalizability and stability over random data splits. If most points lie near the red line, the model generalizes well; if not, overfitting or underfitting might be present."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a83c165",
   "metadata": {},
   "source": [
    "### Summary of Interactions with ChatGPT\n",
    "\n",
    "In our interaction, we discussed a Python code that evaluates the in-sample and out-of-sample performance of a regression model over multiple random splits of the data. The code performs the following steps:\n",
    "\n",
    "1. **Data Splitting**: The dataset (`songs`) is randomly split 100 times into training and testing sets.\n",
    "2. **Model Fitting**: A regression model is fitted to the training set for each iteration, and both the in-sample and out-of-sample R-squared values are calculated.\n",
    "3. **Visualization**: The results are visualized using a scatter plot where in-sample and out-of-sample R-squared values are compared, with a reference line (y=x) to assess model performance consistency.\n",
    "\n",
    "**Key Points**:\n",
    "- **Purpose**: The goal is to assess how well the model generalizes (out-of-sample) compared to how well it fits the training data (in-sample).\n",
    "- **Interpretation**: If the model overfits, in-sample R-squared will be higher than out-of-sample. If it underfits, the opposite occurs.\n",
    "- **Outcome**: The scatter plot helps visualize the stability and generalizability of the model, guiding improvements like addressing overfitting or underfitting.\n",
    "\n",
    "This process demonstrates how model performance varies with different random splits, revealing insights into generalization and the potential need for model adjustments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fd8b35",
   "metadata": {},
   "source": [
    "[Chatbot transcript](https://chatgpt.com/share/67325fa4-f264-800f-83bc-377e4f43d452)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551d9155",
   "metadata": {},
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08616742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.37818209127432456 (original)\n",
      "'Out of sample' R-squared: 0.35055389205977444 (original)\n",
      "'In sample' R-squared:     0.5726118179916575 (gen1_predict_future)\n",
      "'Out of sample' R-squared: 0.11151363354803218 (gen1_predict_future)\n"
     ]
    }
   ],
   "source": [
    "# Model 7: Analysis for Generation 1\n",
    "\n",
    "# Fit an OLS regression model using only Generation 1 data\n",
    "model7_gen1_predict_future = smf.ols(formula=model7_linear_form, \n",
    "                                     data=pokeaman[pokeaman.Generation == 1])\n",
    "model7_gen1_predict_future_fit = model7_gen1_predict_future.fit()\n",
    "\n",
    "# Print in-sample R-squared for model7 using Generation 1 data (model7_fit is assumed to be previously fitted)\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared, \"(original)\")\n",
    "\n",
    "# Calculate out-of-sample R-squared for model7 (predictions on the test dataset, pokeaman_test)\n",
    "y = pokeaman_test.HP  # Actual target values from the test dataset\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y, yhat_model7)[0, 1]**2, \"(original)\")\n",
    "\n",
    "# Print in-sample R-squared for model7 using only Generation 1 data\n",
    "print(\"'In sample' R-squared:    \", model7_gen1_predict_future_fit.rsquared, \"(gen1_predict_future)\")\n",
    "\n",
    "# Calculate out-of-sample R-squared for model7 using Generation 1 predictions for other generations\n",
    "y = pokeaman[pokeaman.Generation != 1].HP  # Actual HP values for non-Generation 1 Pokémon\n",
    "yhat = model7_gen1_predict_future_fit.predict(pokeaman[pokeaman.Generation != 1])  # Predictions for non-Generation 1 data\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y, yhat)[0, 1]**2, \"(gen1_predict_future)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4082ebda",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- Model fitting (Generation 1 only):\n",
    "    - `smf.ols()` fits a regression model to the data from Generation 1 (i.e., only those Pokémon).\n",
    "\n",
    "- In-sample R-squared:\n",
    "    - We first print the in-sample R-squared value from the model (`model7_fit.rsquared`), which tells us how well the model fits the Generation 1 data.\n",
    "\n",
    "- Out-of-sample R-squared (for test data):\n",
    "    - We compute the out-of-sample R-squared by comparing the actual HP values (`pokeaman_test.HP`) with the predicted values (`yhat_model7`) from the test dataset, measuring how well the model generalizes.\n",
    "\n",
    "- In-sample R-squared for Generation 1:\n",
    "    - This is calculated specifically for Generation 1 data using `model7_gen1_predict_future_fit.rsquared`.\n",
    "\n",
    "- Out-of-sample R-squared for other generations:\n",
    "    - The model's predictive power is tested on data that was not used in training (non-Generation 1 Pokémon) by comparing predictions (`yhat`) with actual values (`y`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "543d93e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.37818209127432456 (original)\n",
      "'Out of sample' R-squared: 0.35055389205977444 (original)\n",
      "'In sample' R-squared:     0.3904756578094535 (gen1to5_predict_future)\n",
      "'Out of sample' R-squared: 0.23394915464343125 (gen1to5_predict_future)\n"
     ]
    }
   ],
   "source": [
    "# Model 7: Analysis for Generations 1-5 (excluding Generation 6)\n",
    "\n",
    "# Fit an OLS regression model using data from Generations 1-5 (excluding Generation 6)\n",
    "model7_gen1to5_predict_future = smf.ols(formula=model7_linear_form, \n",
    "                                        data=pokeaman[pokeaman.Generation != 6])\n",
    "model7_gen1to5_predict_future_fit = model7_gen1to5_predict_future.fit()\n",
    "\n",
    "# Print in-sample R-squared for model7 using Generations 1-5 data (model7_fit is assumed to be previously fitted)\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared, \"(original)\")\n",
    "\n",
    "# Calculate out-of-sample R-squared for model7 (using the test dataset, pokeaman_test)\n",
    "y = pokeaman_test.HP  # Actual target values from the test dataset\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y, yhat_model7)[0, 1]**2, \"(original)\")\n",
    "\n",
    "# Print in-sample R-squared for model7 using Generations 1-5 data\n",
    "print(\"'In sample' R-squared:    \", model7_gen1to5_predict_future_fit.rsquared, \"(gen1to5_predict_future)\")\n",
    "\n",
    "# Calculate out-of-sample R-squared for Generation 6 Pokémon\n",
    "y = pokeaman[pokeaman.Generation == 6].HP  # Actual HP values for Generation 6 Pokémon\n",
    "yhat = model7_gen1to5_predict_future_fit.predict(pokeaman[pokeaman.Generation == 6])  # Predictions for Generation 6 data\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y, yhat)[0, 1]**2, \"(gen1to5_predict_future)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c7cb6e",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- **Model fitting (Generations 1-5):**\n",
    "  - A regression model (`model7`) is fitted to Pokémon data from Generations 1 to 5, excluding Generation 6.\n",
    "\n",
    "- **In-sample R-squared:**\n",
    "  - Prints the in-sample R-squared value for `model7` when applied to the Generation 1-5 data.\n",
    "\n",
    "- **Out-of-sample R-squared for Generation 6:**\n",
    "  - Calculates the R-squared for how well the model generalizes to Pokémon from Generation 6 by comparing actual HP values (`y`) with the model's predictions (`yhat`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c1f2c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3326310334310908 (original)\n",
      "'Out of sample' R-squared: 0.29572460427079933 (original)\n",
      "'In sample' R-squared:     0.4433880517727282 (gen1_predict_future)\n",
      "'Out of sample' R-squared: 0.1932858534276128 (gen1_predict_future)\n"
     ]
    }
   ],
   "source": [
    "# Model 6: Analysis for Generation 1 (same procedure as above but using model6)\n",
    "\n",
    "# Fit an OLS regression model using only Generation 1 data for model6\n",
    "model6_gen1_predict_future = smf.ols(formula=model6_linear_form, \n",
    "                                     data=pokeaman[pokeaman.Generation == 1])\n",
    "model6_gen1_predict_future_fit = model6_gen1_predict_future.fit()\n",
    "\n",
    "# Print in-sample R-squared for model6 using Generation 1 data\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared, \"(original)\")\n",
    "\n",
    "# Calculate out-of-sample R-squared for model6 (predictions on the test dataset, pokeaman_test)\n",
    "y = pokeaman_test.HP  # Actual target values from the test dataset\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y, yhat_model6)[0, 1]**2, \"(original)\")\n",
    "\n",
    "# Print in-sample R-squared for model6 using only Generation 1 data\n",
    "print(\"'In sample' R-squared:    \", model6_gen1_predict_future_fit.rsquared, \"(gen1_predict_future)\")\n",
    "\n",
    "# Calculate out-of-sample R-squared for model6 using Generation 1 predictions for other generations\n",
    "y = pokeaman[pokeaman.Generation != 1].HP  # Actual HP values for non-Generation 1 Pokémon\n",
    "yhat = model6_gen1_predict_future_fit.predict(pokeaman[pokeaman.Generation != 1])  # Predictions for non-Generation 1 data\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y, yhat)[0, 1]**2, \"(gen1_predict_future)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc6ce61",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- **Model fitting (Generation 1 only):**\n",
    "  - This time the regression is done using `model6` on Generation 1 Pokémon.\n",
    "\n",
    "- **In-sample R-squared for model6:**\n",
    "  - The R-squared is calculated for how well `model6` fits Generation 1 data.\n",
    "\n",
    "- **Out-of-sample R-squared for other generations:**\n",
    "  - As before, the model's ability to predict HP values for non-Generation 1 data is evaluated by comparing predictions with actual values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfac2efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3326310334310908 (original)\n",
      "'Out of sample' R-squared: 0.29572460427079933 (original)\n",
      "'In sample' R-squared:     0.33517279824114776 (gen1to5_predict_future)\n",
      "'Out of sample' R-squared: 0.26262690178799936 (gen1to5_predict_future)\n"
     ]
    }
   ],
   "source": [
    "# Model 6: Analysis for Generations 1-5 (excluding Generation 6)\n",
    "\n",
    "# Fit an OLS regression model using data from Generations 1-5 (excluding Generation 6) for model6\n",
    "model6_gen1to5_predict_future = smf.ols(formula=model6_linear_form, \n",
    "                                        data=pokeaman[pokeaman.Generation != 6])\n",
    "model6_gen1to5_predict_future_fit = model6_gen1to5_predict_future.fit()\n",
    "\n",
    "# Print in-sample R-squared for model6 using Generations 1-5 data\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared, \"(original)\")\n",
    "\n",
    "# Calculate out-of-sample R-squared for model6 (using the test dataset, pokeaman_test)\n",
    "y = pokeaman_test.HP  # Actual target values from the test dataset\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y, yhat_model6)[0, 1]**2, \"(original)\")\n",
    "\n",
    "# Print in-sample R-squared for model6 using Generations 1-5 data\n",
    "print(\"'In sample' R-squared:    \", model6_gen1to5_predict_future_fit.rsquared, \"(gen1to5_predict_future)\")\n",
    "\n",
    "# Calculate out-of-sample R-squared for Generation 6 Pokémon\n",
    "y = pokeaman[pokeaman.Generation == 6].HP  # Actual HP values for Generation 6 Pokémon\n",
    "yhat = model6_gen1to5_predict_future_fit.predict(pokeaman[pokeaman.Generation == 6])  # Predictions for Generation 6 data\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y, yhat)[0, 1]**2, \"(gen1to5_predict_future)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8d3878",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- **Model fitting (Generations 1-5):**\n",
    "  - This fits `model6` to data from Generations 1-5 (excluding Generation 6).\n",
    "\n",
    "- **In-sample R-squared:**\n",
    "  - The R-squared for this model is calculated to measure how well `model6` fits the data from Generations 1-5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab58c82",
   "metadata": {},
   "source": [
    "we are evaluating how well models predict a target variable (likely Pokémon HP, as indicated by the use of pokeaman.HP) across different subsets of data.\n",
    "\n",
    "Key Concepts Illustrated:\n",
    "- Model fitting: How the model adjusts to the data to make predictions.\n",
    "- In-sample vs. Out-of-sample: The distinction between how well the model performs on the data it was trained on versus how well it generalizes to new data.\n",
    "- R-squared: A measure of how well the model explains the variance in the target variable (HP in this case).\n",
    "\n",
    "It is showing an analysis of a model’s predictive power, first for a specific generation (Generation 1) and then for broader subsets of data (such as generations 1-5 and Generation 6)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900428fe",
   "metadata": {},
   "source": [
    "#### **Comparison of Linear Regression Models: `model7_fit` vs `model6_fit`**\n",
    "\n",
    "1. **Complexity**\n",
    "**Definition**: Complexity refers to the number of predictors and interactions in the model, as well as how intricate the relationships modeled are.\n",
    "\n",
    "- **Model 7 (`model7_fit`)**:\n",
    "  - Likely involves a larger number of predictors or more complex relationships (e.g., interactions, non-linear terms).\n",
    "  - Higher complexity increases the risk of **overfitting**, where the model performs well on training data but poorly on unseen data.\n",
    "\n",
    "- **Model 6 (`model6_fit`)**:\n",
    "  - Likely simpler, either with fewer predictors or more straightforward relationships.\n",
    "  - A simpler model has a lower risk of overfitting and is easier to understand.\n",
    "\n",
    "**Comparison**:  \n",
    "- If `model7` has additional terms or interactions compared to `model6`, it will have higher complexity, making it more flexible but at the cost of potential overfitting.  \n",
    "- `model6` is likely better suited for datasets with smaller sample sizes or when parsimony (using fewer predictors) is desired.\n",
    "\n",
    "---\n",
    "\n",
    "2. **Interpretability**\n",
    "**Definition**: Interpretability refers to how easily the model’s results can be understood by humans.\n",
    "\n",
    "- **Model 7 (`model7_fit`)**:\n",
    "  - A higher number of predictors or interactions can make the model harder to interpret.\n",
    "  - Coefficients might be harder to explain if they represent interaction effects or transformations.\n",
    "\n",
    "- **Model 6 (`model6_fit`)**:\n",
    "  - Simpler models are easier to interpret because they include fewer terms, and the relationships between variables are more direct.\n",
    "  - Useful for understanding the primary drivers of the outcome (HP in this case).\n",
    "\n",
    "**Comparison**:  \n",
    "- If simplicity and explainability are priorities (e.g., for business stakeholders or non-technical audiences), `model6` will likely be preferred.  \n",
    "- If capturing subtle patterns is more important than interpretability, `model7` may be more useful.\n",
    "\n",
    "---\n",
    "\n",
    "3. **Generalizability**\n",
    "**Definition**: Generalizability is the model's ability to perform well on unseen data, measured here by out-of-sample R-squared.\n",
    "\n",
    "- **Model 7 (`model7_fit`)**:\n",
    "  - Higher complexity increases the likelihood of overfitting the training data, which can reduce generalizability.\n",
    "  - If `model7` has strong out-of-sample R-squared values, it means the additional complexity is beneficial and captures meaningful relationships.\n",
    "\n",
    "- **Model 6 (`model6_fit`)**:\n",
    "  - Simpler models tend to generalize better because they avoid capturing noise in the training data.\n",
    "  - If `model6` has comparable or higher out-of-sample R-squared values than `model7`, it suggests that `model7`’s added complexity was unnecessary.\n",
    "\n",
    "**Comparison**:  \n",
    "- Generalizability can be assessed by comparing the out-of-sample R-squared values of `model7` and `model6`.  \n",
    "- If `model7` has a significantly higher out-of-sample R-squared, it justifies its complexity. Otherwise, `model6` is preferred for its balance of simplicity and predictive power.\n",
    "\n",
    "---\n",
    "\n",
    "#### Conclusion\n",
    "- **Model 7 (`model7_fit`)** may offer more flexibility and better in-sample performance due to its complexity but risks being harder to interpret and less generalizable.\n",
    "- **Model 6 (`model6_fit`)** is likely easier to interpret and more robust for generalization, especially if the dataset is smaller or noisy.\n",
    "\n",
    "---\n",
    "\n",
    "**Recommendation**\n",
    "\n",
    "Use the **out-of-sample R-squared** to quantify generalizability and choose the model that balances complexity with performance. If both models generalize equally well, prioritize the simpler and more interpretable model, `model6`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bd843b",
   "metadata": {},
   "source": [
    "### Summary of Interactions with ChatGPT\n",
    "\n",
    "Topic Overview:\n",
    "- You provided a series of Python code for evaluating the performance of regression models (`model7` and `model6`) in predicting Pokémon HP (Hit Points) using different subsets of data (based on generations).\n",
    "\n",
    "**Key Points**:\n",
    "\n",
    "1. **Model 7 Analysis**:\n",
    "   - **Generation 1**: You fitted a regression model using only Generation 1 Pokémon and evaluated both the in-sample and out-of-sample R-squared values.\n",
    "   - **Generations 1-5**: The model was also tested using data from Generations 1 through 5, and predictions were made for Generation 6, with R-squared values calculated to see how well the model generalizes.\n",
    "\n",
    "2. **Model 6 Analysis**:\n",
    "   - A similar analysis was performed using a second model (`model6`). You fitted the model to Generation 1 data and evaluated its in-sample and out-of-sample R-squared values for both non-Generation 1 Pokémon and Generation 6 Pokémon.\n",
    "\n",
    "3. **R-Squared Evaluation**:\n",
    "   - **In-sample R-squared** measures how well the model fits the data it was trained on.\n",
    "   - **Out-of-sample R-squared** measures the model's predictive power on unseen data (either from different generations or a test dataset).\n",
    "   - The analysis allows you to assess the models' generalizability to new, unseen data.\n",
    "\n",
    "**Code Explanations**:\n",
    "- For each model, you fitted it to subsets of the data (e.g., Generation 1 or Generations 1-5) and used those models to predict Pokémon HP for other generations.\n",
    "- R-squared values were calculated for both in-sample (training) and out-of-sample (test or other generations) to evaluate how well each model performed.\n",
    "\n",
    "**Conclusion**:\n",
    "You are evaluating the generalization performance of two regression models (`model6` and `model7`) on different Pokémon generations to understand how well they can predict HP values for new, unseen Pokémon from different generations.\n",
    "\n",
    "\n",
    "We then compared two linear regression models, `model7_fit` and `model6_fit`, across three critical aspects:\n",
    "\n",
    "1. Complexity  \n",
    "   - Model 7:  \n",
    "     Likely more complex, incorporating additional predictors or interactions. This increases flexibility but also raises the risk of overfitting.  \n",
    "   - Model 6:  \n",
    "     Simpler, with fewer predictors or relationships. It is easier to manage, especially for smaller datasets, and has a lower risk of overfitting.\n",
    "\n",
    "2. Interpretability  \n",
    "   - Model 6:  \n",
    "     More interpretable due to its simplicity, making it ideal for communicating results to non-technical audiences.  \n",
    "   - Model 7:  \n",
    "     Harder to interpret due to additional terms or interactions. While it may provide deeper insights, it sacrifices clarity.\n",
    "\n",
    "3. Generalizability  \n",
    "   - Key Metric: Out-of-sample R-squared.  \n",
    "     - Model 6: Expected to generalize better because simpler models tend to avoid capturing noise in the data.  \n",
    "     - Model 7: May generalize better if its added complexity captures meaningful relationships without overfitting.\n",
    "\n",
    "Conclusion  \n",
    "- Model 7 is best for capturing subtle patterns if the added complexity is justified and manageable.  \n",
    "- Model 6 is preferred for simplicity, interpretability, and robustness, especially when both models generalize equally well.  \n",
    "\n",
    "This discussion highlighted the trade-offs between complexity and interpretability, emphasizing the importance of evaluating models based on their performance on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f1b013",
   "metadata": {},
   "source": [
    "[Chatbot transcript](https://chatgpt.com/share/67326fe9-2bbc-800f-9583-304666424225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ed25c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
